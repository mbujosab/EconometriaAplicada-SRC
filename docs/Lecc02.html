<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="es-es" xml:lang="es-es">
<head>
<!-- 2024-09-30 lun 16:30 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Econometría Aplicada. Lección 2</title>
<meta name="author" content="Marcos Bujosa" />
<meta name="generator" content="Org Mode" />
<style type="text/css">
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Econometría Aplicada. Lección 2</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgbd72680">Carga de algunos módulos de python</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgca20c2b">1. Descomposición estructural de una serie temporal</a>
<ul>
<li><a href="#orgc468f75">1.1. Tendencia determinista <i>lineal</i></a></li>
<li><a href="#orgfa62434">1.2. Tendencia determinista <i>cuadrática</i></a></li>
<li><a href="#org87b7059">1.3. Tendencia cuadrática más estacionalidad determinista mediante <i>dummies</i></a>
<ul>
<li><a href="#orgf413664">1.3.1. Ajuste y componente irregular \(\boldsymbol{e}=\boldsymbol{y}-\boldsymbol{t}-\boldsymbol{s}\)</a></li>
<li><a href="#org59ae9a9">1.3.2. Valoración de modelos con componentes deterministas</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgf59aaa1">2. Perturbaciones no esféricas</a>
<ul>
<li><a href="#org87bd2b0">2.1. Test de autocorrelación de Breusch y Godfrey</a></li>
<li><a href="#org61a4266">2.2. Errores estándar robustos</a></li>
<li><a href="#orgec246c8">2.3. Modelo del error</a></div>
</div>
<div class="ABSTRACT" id="org203be33">
<p>
En esta lección veremos algunos modelos de regresión con series
temporales; en particular la estimación de componentes (no
observables) con modelos deterministas. También los efectos de la
autocorrelación en las perturbaciones y como lidiar con ellos.
</p>

</div>

<ul class="org-ul">
<li><a href="https://mbujosab.github.io/EconometriaAplicada-SRC/Lecc02.html">lección en html</a></li>
<li><a href="https://mybinder.org/v2/gh/mbujosab/EconometriaAplicada-SRC/HEAD?labpath=Lecc02.ipynb">lección en mybinder</a></li>
</ul>
<div id="outline-container-orgbd72680" class="outline-4">
<h4 id="orgbd72680">Carga de algunos módulos de python</h4>
<div class="outline-text-4" id="text-orgbd72680">
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Importamos algunos m&#243;dulos de python</span>
<span style="color: #0000FF;">import</span> numpy <span style="color: #0000FF;">as</span> np <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">linear algebra</span>
<span style="color: #0000FF;">import</span> pandas <span style="color: #0000FF;">as</span> pd <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">dataframe processing</span>
<span style="color: #0000FF;">import</span> statsmodels.api <span style="color: #0000FF;">as</span> sm  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">modelos estad&#237;sticos</span>
<span style="color: #0000FF;">import</span> matplotlib <span style="color: #0000FF;">as</span> mpl
<span style="color: #0000FF;">import</span> matplotlib.pyplot <span style="color: #0000FF;">as</span> plt <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">data visualization</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">definimos par&#225;metros para mejorar los gr&#225;ficos</span>
mpl.rc(<span style="color: #008000;">'text'</span>, usetex=<span style="color: #D0372D;">True</span>)
mpl.rc(<span style="color: #008000;">'text.latex'</span>, preamble=r<span style="color: #008000;">'\usepackage{amsmath}'</span>)
<span style="color: #0000FF;">from</span> matplotlib <span style="color: #0000FF;">import</span> rcParams
<span style="color: #BA36A5;">rcParams</span>[<span style="color: #008000;">'figure.figsize'</span>] = 15,5
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Usar&#233; la siguiente funci&#243;n para transformar salidas en \LaTeX{} de statsmodels a ficheros png </span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">que incluir&#233; en las transparencias</span>
<span style="color: #0000FF;">from</span> sympy.printing.preview <span style="color: #0000FF;">import</span> preview
<span style="color: #0000FF;">def</span> <span style="color: #006699;">repr_png</span>(tex, ImgFile):
    <span style="color: #BA36A5;">preamble</span> = <span style="color: #008000;">"</span><span style="color: #D0372D;">\\</span><span style="color: #008000;">documentclass[10pt,preview]{standalone}</span><span style="color: #D0372D;">\n</span><span style="color: #008000;">"</span> \
        <span style="color: #008000;">"</span><span style="color: #D0372D;">\\</span><span style="color: #008000;">usepackage{booktabs,amsmath,amsfonts}</span><span style="color: #D0372D;">\\</span><span style="color: #008000;">begin{document}"</span>    
    preview(tex, filename=ImgFile, viewer=<span style="color: #008000;">'file'</span>, preamble=preamble, dvioptions=[<span style="color: #008000;">'-D'</span>,<span style="color: #008000;">'250'</span>])
</pre>
</div>
</div>
<ul class="org-ul">
<li><a id="orgdb49bf9"></a>Lectura datos: Internat. airline passengers. Monthly totals in thousands. Jan 49 – Dec 60<br />
<div class="outline-text-5" id="text-orgdb49bf9">
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Leemos los datos de un fichero csv y generamos un dataframe de pandas cuyo &#237;ndice es el tiempo</span>
<span style="color: #BA36A5;">OrigData</span> = pd.read_csv(<span style="color: #008000;">'./database/Datasets-master/airline-passengers.csv'</span>)
<span style="color: #BA36A5;">OrigData</span>[<span style="color: #008000;">'Month'</span>] = pd.to_datetime(OrigData[<span style="color: #008000;">'Month'</span>])
<span style="color: #BA36A5;">OrigData</span> = OrigData.set_index([<span style="color: #008000;">'Month'</span>])
<span style="color: #006FE0;">print</span>(OrigData.head())
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Creamos un dataframe con el mismo &#237;ndice temporal de los datos originales pero con los datos en logaritmos</span>
<span style="color: #BA36A5;">TransformedData</span> = pd.DataFrame(index=OrigData.index)
<span style="color: #BA36A5;">TransformedData</span>[<span style="color: #008000;">'dataLog'</span>] = np.log(OrigData[<span style="color: #008000;">'Passengers'</span>])
<span style="color: #006FE0;">print</span>(TransformedData.head())
</pre>
</div>
</div>
</li>
</ul>
</div>
<div id="outline-container-orgca20c2b" class="outline-2">
<h2 id="orgca20c2b"><span class="section-number-2">1.</span> Descomposición estructural de una serie temporal</h2>
<div class="outline-text-2" id="text-1">
<p>
En la lección anterior vimos que una estrategia para analizar series
temporales es transformar los datos para
</p>

<ol class="org-ol">
<li>primero lograr que sean "<b><i>estacionarios</i></b>" y</li>
<li>después, mediante más transformaciones, lograr una secuencia de
"<b>ruido blanco</b>" (este segundo paso aún no lo hemos abordado)</li>
</ol>
<p>
(<i>recuerde que las expresiones "datos estacionarios" o secuencia de
"ruido blanco" son un abuso del lenguaje</i>).
</p>

<p>
Pero existe otro enfoque que pretende descomponer la serie temporal en
los siguientes componentes <i>"no observables"</i> (o en un subconjunto de
ellos):
</p>

<p>
\[\boldsymbol{y} = \boldsymbol{t} + \boldsymbol{c} + \boldsymbol{s} + \boldsymbol{e}\]
</p>

<p>
donde:
</p>

<dl class="org-dl">
<dt>La tendencia "\(\boldsymbol{t}\)"</dt><dd>recoge la lenta evolución de la
media a <i>largo plazo</i>.</dd>

<dt>El componente estacional "\(\boldsymbol{s}\)"</dt><dd>recoge las
oscilaciones periódicas que se repiten regularmente en ciclos
estacionales (de año en año, o de semana en semana, etc.).</dd>

<dt>El componente cíclico "\(\boldsymbol{c}\)"</dt><dd>Cuando aparece
explícitamente en el modelo, \(\boldsymbol{c}\) recoge las
oscilaciones a medio plazo. Es decir, aquellas de un plazo más largo
que las oscilaciones estacionales, pero más corto que la tendencia
de largo plazo. Si está ausente, dichas oscilaciones suelen aparecer
en el componente de la tendencia, que entonces también podemos
denominar <i>tendencia-ciclo</i>.</dd>

<dt>El componente irregular "\(\boldsymbol{e}\)"</dt><dd>recoge las
oscilaciones no captadas por el resto de componentes, ya que debe
cumplir la siguiente identidad: \(\boldsymbol{e} = \boldsymbol{y} -
  \boldsymbol{t} - \boldsymbol{c} - \boldsymbol{s}\).</dd>
</dl>

<p>
Ajuste aceptable si (como poco) el componente irregular
\(\boldsymbol{e}\) parece "<i>estacionario</i>".
</p>
</div>
<div id="outline-container-orgc468f75" class="outline-3">
<h3 id="orgc468f75"><span class="section-number-3">1.1.</span> Tendencia determinista <i>lineal</i></h3>
<div class="outline-text-3" id="text-1-1">
<div class="org-src-container">
<pre class="src src-jupyter-python" id="org06e8a6f"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Ajustamos por MCO una tendencia linea. </span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Para ello, primero creamos un DataFrame con el regresando y los regresores del modelo</span>
<span style="color: #BA36A5;">datosModelo1</span> = TransformedData[[<span style="color: #008000;">'dataLog'</span>]].copy()
<span style="color: #BA36A5;">nsample</span> = <span style="color: #006FE0;">len</span>(datosModelo1)
<span style="color: #BA36A5;">datosModelo1</span>[<span style="color: #008000;">'cte'</span>] = [1]*nsample
<span style="color: #BA36A5;">datosModelo1</span>[<span style="color: #008000;">'time'</span>] = np.linspace(1, nsample, nsample)
<span style="color: #BA36A5;">model1</span> = sm.OLS(datosModelo1[<span style="color: #008000;">'dataLog'</span>], datosModelo1[[<span style="color: #008000;">'cte'</span>, <span style="color: #008000;">'time'</span>]])
<span style="color: #BA36A5;">results1</span> = model1.fit()
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #8D8D84;">#</span><span style="color: #8D8D84; font-style: italic;">A&#241;adimos al DataFrame =datosModelo1= la tendencia ajustada, los residuos y la diferencia estacional de los residuos.</span>
<span style="color: #BA36A5;">datosModelo1</span>[<span style="color: #008000;">'yhat'</span>] = datosModelo1[<span style="color: #008000;">'cte'</span>]*results1.params[<span style="color: #008000;">'cte'</span>]+datosModelo1[<span style="color: #008000;">'time'</span>]*results1.params[<span style="color: #008000;">'time'</span>]
<span style="color: #BA36A5;">datosModelo1</span>[<span style="color: #008000;">'ehat'</span>] = results1.resid
<span style="color: #BA36A5;">datosModelo1</span>[<span style="color: #008000;">'ehatDiff12'</span>] = datosModelo1[<span style="color: #008000;">'ehat'</span>].diff(12)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Dibujamos los datos junto a la tendencia estimada</span>
plt.plot(datosModelo1[<span style="color: #008000;">'dataLog'</span>])
plt.plot(results1.fittedvalues)
plt.grid()  
plt.ylabel(r<span style="color: #008000;">"Log-Passengers, ($\ln\boldsymbol{x}$) "</span>)
</pre>
</div>

<p>
El modelo de tendencia más simple es la recta de regresión (el
regresor no constante es el índice \(t\)):
</p>

<p>
\[\ln{y_t}=\underbrace{\beta_1+\beta_2\cdot t}_{\text{tendencia}} + e_t; \quad t=1:114\]
</p>

<div id="org78e1d50" class="figure">
<p><img src="./img/lecc02/airlinepass+linearTrend.png" alt="airlinepass+linearTrend.png" width="900px" />
</p>
</div>

<p>
\[\widehat{\ln{y_t}}=4.8137+0.01\cdot\big(t\big), \qquad t=1:114\]
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #006FE0;">print</span>(results1.summary()) 
</pre>
</div>



<div id="org380edb4" class="figure">
<p><img src="./img/lecc02/resultsModel1.png" alt="resultsModel1.png" width="600px" />
</p>
</div>



<p>
<b><span class="underline">Componente irregular</span></b>
</p>
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Gr&#225;fico de los residuos del ajuste.</span>
plt.grid()  
plt.plot(results1.resid)
</pre>
</div>


<div id="org03c2da9" class="figure">
<p><img src="./img/lecc02/airlinepass+irreg.png" alt="airlinepass+irreg.png" width="900px" />
</p>
</div>

<p>
En este caso, el modelo 
</p>

<p>
\[\boldsymbol{y} = \boldsymbol{t} + \boldsymbol{e}\]
</p>

<p>
donde \(\boldsymbol{t}\) es una tendencia lineal no
es un ajuste satisfactorio, pues el <i>componente irregular</i>
\[\boldsymbol{e}=\boldsymbol{y}-\boldsymbol{t}\]
no tiene la apariencia de realización de un proceso estacionario.
</p>


<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Gr&#225;fico de la diferencia estacional de los residuos del ajuste.</span>
plt.grid()  
plt.plot(datosModelo1[<span style="color: #008000;">'ehatDiff12'</span>])
</pre>
</div>

<p>
Adicionalmente podemos ver que diferencia de orden 12 del componente
irregular parece mostrar un componente cíclico con un periodo de unos
4 años.
</p>


<div id="org3ef120a" class="figure">
<p><img src="./img/lecc02/airlinepass+irregDiff12.png" alt="airlinepass+irregDiff12.png" width="900px" />
</p>
</div>

<p>
En el siguiente ejercicio probaremos con una tendencia cuadrática&#x2026;
</p>
</div>
</div>
<div id="outline-container-orgfa62434" class="outline-3">
<h3 id="orgfa62434"><span class="section-number-3">1.2.</span> Tendencia determinista <i>cuadrática</i></h3>
<div class="outline-text-3" id="text-1-2">
<div class="org-src-container">
<pre class="src src-jupyter-python" id="org1fb6e06"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">creamos un DataFrame con el regresando y los regresores del modelo :results silent.</span>
<span style="color: #BA36A5;">datosModelo2</span> = TransformedData[[<span style="color: #008000;">'dataLog'</span>]].copy()
<span style="color: #BA36A5;">nsample</span> = <span style="color: #006FE0;">len</span>(datosModelo1)
<span style="color: #BA36A5;">datosModelo2</span>[<span style="color: #008000;">'cte'</span>] = [1]*nsample
<span style="color: #BA36A5;">datosModelo2</span>[<span style="color: #008000;">'time'</span>] = np.linspace(1, nsample, nsample)
<span style="color: #BA36A5;">datosModelo2</span>[<span style="color: #008000;">'sq_time'</span>] = [t**2 <span style="color: #0000FF;">for</span> t <span style="color: #0000FF;">in</span> datosModelo2[<span style="color: #008000;">'time'</span>]]
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Ajustamos por MCO una tendencia cuadr&#225;tica a los datos.</span>
<span style="color: #BA36A5;">model2</span> = sm.OLS(datosModelo1[<span style="color: #008000;">'dataLog'</span>], datosModelo2[[<span style="color: #008000;">'cte'</span>, <span style="color: #008000;">'time'</span>, <span style="color: #008000;">'sq_time'</span>]])
<span style="color: #BA36A5;">results2</span> = model2.fit()
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">A&#241;adimos al DataFrame 'datosModelo2' la tendencia ajustada, los residuos y la diferencia estacional de los residuos.</span>
<span style="color: #BA36A5;">datosModelo2</span>[<span style="color: #008000;">'yhat'</span>] = results2.fittedvalues
<span style="color: #BA36A5;">datosModelo2</span>[<span style="color: #008000;">'ehat'</span>] = results2.resid
<span style="color: #BA36A5;">datosModelo2</span>[<span style="color: #008000;">'ehatDiff12'</span>] = datosModelo2[<span style="color: #008000;">'ehat'</span>].diff(12)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Dibujamos los datos junto a la tendencia estimada.</span>
plt.plot(datosModelo1[<span style="color: #008000;">'dataLog'</span>])
plt.plot(results2.fittedvalues)
plt.grid()  
plt.ylabel(r<span style="color: #008000;">"Log-Passengers, ($\ln\boldsymbol{x}$) "</span>)
</pre>
</div>

<p>
\[\ln{y_t}=\underbrace{\beta_1+\beta_2\cdot t + \beta_3\cdot t^2}_{\text{tendencia}} + e_t; \quad t=1:114\]
</p>


<div id="orgb94adf4" class="figure">
<p><img src="./img/lecc02/airlinepass+quadraticTrend.png" alt="airlinepass+quadraticTrend.png" width="900px" />
</p>
</div>

<p>
\[\widehat{\ln{y_t}}=4.7364+(0.0132)\cdot t +(-2.191e-05)\cdot t^2, \qquad t=1:114\]
</p>



<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #006FE0;">print</span>(results2.summary()) 
</pre>
</div>


<div id="org1ca998d" class="figure">
<p><img src="./img/lecc02/resultsModel2.png" alt="resultsModel2.png" width="600px" />
</p>
</div>


<p>
<b><span class="underline">Componente irregular</span></b>
</p>
<div class="org-src-container">
<pre class="src src-jupyter-python">plt.grid()  
plt.plot(results2.resid)
</pre>
</div>



<div id="orgc6bf0c9" class="figure">
<p><img src="./img/lecc02/airlinepass+irreg2.png" alt="airlinepass+irreg2.png" width="900px" />
</p>
</div>

<p>
De manera análoga al caso anterior, el modelo
</p>

<p>
\[\boldsymbol{y} = \boldsymbol{t} + \boldsymbol{e}\]
</p>

<p>
donde \(\boldsymbol{t}\) ahora es una <i>tendencia
cuadrática</i> tampoco es un ajuste satisfactorio, pues el componente
irregular \(\boldsymbol{e}\) sigue sin parecerse a la realización de un
proceso estacionario.
</p>


<div class="org-src-container">
<pre class="src src-jupyter-python">plt.grid()  
plt.plot(datosModelo2[<span style="color: #008000;">'ehatDiff12'</span>])
</pre>
</div>

<p>
También en este modelo la diferencia de orden 12 del componente
irregular muestra un componente cíclico con un periodo de unos 4 años.
</p>


<div id="orgac2de1d" class="figure">
<p><img src="./img/lecc02/airlinepass+irregDiff12.png" alt="airlinepass+irregDiff12.png" width="900px" />
</p>
</div>

<p>
Para obtener una <i>tendencia-ciclo</i> que capte este ciclo, son
necesarios procedimientos más sofisticados (por ejemplo TRAMO-SEATS, o
X13-ARIMA, o STAMP, o LDHR, o E4, etc.) que estiman tendencias y
componentes estacionales estocásticos.
</p>

<p>
En el siguiente ejercicio estimaremos un <b>componente estacional
determinista</b> (junto a una tendencia cuadrática determinista).
</p>
</div>
</div>
<div id="outline-container-org87b7059" class="outline-3">
<h3 id="org87b7059"><span class="section-number-3">1.3.</span> Tendencia cuadrática más estacionalidad determinista mediante <i>dummies</i></h3>
<div class="outline-text-3" id="text-1-3">
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Creamos un dataframe con los datos y los regresores 'cte', 't' y ' :results silentt^2'</span>
<span style="color: #BA36A5;">df</span> = TransformedData[[<span style="color: #008000;">'dataLog'</span>]].copy()
<span style="color: #BA36A5;">nsample</span> = <span style="color: #006FE0;">len</span>(df)
<span style="color: #BA36A5;">df</span>[<span style="color: #008000;">'cte'</span>]     = [1]*nsample
<span style="color: #BA36A5;">df</span>[<span style="color: #008000;">'time'</span>]    = np.linspace(1, nsample, nsample)
<span style="color: #BA36A5;">df</span>[<span style="color: #008000;">'sq_time'</span>] = [t**2 <span style="color: #0000FF;">for</span> t <span style="color: #0000FF;">in</span> df[<span style="color: #008000;">'time'</span>]]
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Creamos las /dummies/ estacionales</span>
<span style="color: #0000FF;">from</span> statsmodels.tsa.deterministic <span style="color: #0000FF;">import</span> Seasonality
<span style="color: #BA36A5;">seas_gen</span> = Seasonality(12, initial_period=1)
<span style="color: #BA36A5;">seasonalDummies</span> = seas_gen.in_sample(df.index)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">Creamos un dataframe con el regresando y todos los regresores del modelo</span>
<span style="color: #BA36A5;">datosModelo3</span> = pd.concat([df, seasonalDummies],axis=1)
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">realizamos la regresi&#243;n de la primera columna ('dataLog') sobre el resto de columnas del dataframe.</span>
<span style="color: #BA36A5;">model3</span> = sm.OLS(datosModelo3[<span style="color: #008000;">'dataLog'</span>], datosModelo3.iloc[:,1:-1])
<span style="color: #BA36A5;">results3</span> = model3.fit()
</pre>
</div>


<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">La combinaci&#243;n lineal de los regresores 'cte', 'time' y 'sq_time' usando los correspondientes</span>
<span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">par&#225;metros estimados nos da el componente de tendencia (determinista) estimado. </span>
<span style="color: #BA36A5;">TrendComp</span> = datosModelo3[[<span style="color: #008000;">'cte'</span>,<span style="color: #008000;">'time'</span>,<span style="color: #008000;">'sq_time'</span>]].dot(results3.params[[<span style="color: #008000;">'cte'</span>,<span style="color: #008000;">'time'</span>,<span style="color: #008000;">'sq_time'</span>]])
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #BA36A5;">rcParams</span>[<span style="color: #008000;">'figure.figsize'</span>] = 15,4
plt.plot(datosModelo1[<span style="color: #008000;">'dataLog'</span>])
plt.plot(TrendComp)
plt.grid()  
plt.ylabel(r<span style="color: #008000;">"Log-Passengers, ($\ln\boldsymbol{x}$) "</span>)
</pre>
</div>


<div id="orgf821f46" class="figure">
<p><img src="./img/lecc02/airlinepass+TrendC.png" alt="airlinepass+TrendC.png" width="900px" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #BA36A5;">SeasonalComp</span> = (seasonalDummies.iloc[:,:-1]).dot(results3.params[3:])
plt.grid()  
plt.plot(SeasonalComp)
</pre>
</div>


<div id="org43f8db0" class="figure">
<p><img src="./img/lecc02/airlinepass+SeasonalC.png" alt="airlinepass+SeasonalC.png" width="900px" />
</p>
</div>
</div>
<div id="outline-container-orgf413664" class="outline-4">
<h4 id="orgf413664"><span class="section-number-4">1.3.1.</span> Ajuste y componente irregular \(\boldsymbol{e}=\boldsymbol{y}-\boldsymbol{t}-\boldsymbol{s}\)</h4>
<div class="outline-text-4" id="text-1-3-1">
<div class="org-src-container">
<pre class="src src-jupyter-python">plt.grid()  
plt.plot(datosModelo3[<span style="color: #008000;">'dataLog'</span>])
plt.plot(TrendComp + SeasonalComp)
</pre>
</div>


<div id="orgf880fb6" class="figure">
<p><img src="./img/lecc02/airlinepass+yhat.png" alt="airlinepass+yhat.png" width="900px" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python">plt.grid()  
plt.plot(results3.resid)
</pre>
</div>


<div id="org3b28887" class="figure">
<p><img src="./img/lecc02/airlinepass+IrregC.png" alt="airlinepass+IrregC.png" width="900px" />
</p>
</div>
</div>
</div>
<div id="outline-container-org59ae9a9" class="outline-4">
<h4 id="org59ae9a9"><span class="section-number-4">1.3.2.</span> Valoración de modelos con componentes deterministas</h4>
<div class="outline-text-4" id="text-1-3-2">
<ul class="org-ul">
<li>Estos modelos resultan útiles para realizar un análisis descriptivo.</li>

<li>Pero suelen funcionar bastante mal como herramienta de predicción:

<ul class="org-ul">
<li>no tienen en cuenta la dependencia inter-temporal de los datos (se
han estimado mediante una regresión como si los datos hubieran
sido de sección cruzada)</li>

<li>Por ejemplo, a la hora de prever el dato de enero de 1961, en este
modelo pesa tanto el dato de enero de 1949 como el dato de enero
de 1960.</li>
</ul></li>
</ul>

<p>
En general, para que los modelos funcionen bien en predicción deben
<i>dar un mayor peso a los datos recientes</i> frente a los datos alejados
en el tiempo.

</p>

<p>
Pero sigamos explorando este modelo&#x2026;

</p>

<p>
<b>Hay parámetros no significativos&#x2026;</b> (p-valores para dummies enero,
febrero y octubre).
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python">repr_png(results3.summary().as_latex(), <span style="color: #008000;">"./img/lecc02/resultsModel3.png"</span>)
</pre>
</div>

<div>
<img src="./img/lecc02/resultsModel3.png" width="400" class="center"/>
</div>

<p>

</p>

<p>
<b>podemos eliminarlos secuencialmente</b> (quitando cada vez la variable de mayor p-valor)
</p>
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #0000FF;">import</span> operator
<span style="color: #0000FF;">def</span> <span style="color: #006699;">remove_most_insignificant</span>(df, results):
    <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">use operator to find the key which belongs to the maximum value in the dictionary:</span>
    <span style="color: #BA36A5;">max_p_value</span> = <span style="color: #006FE0;">max</span>(results.pvalues.items(), key=operator.itemgetter(1))[0]
    <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">this is the feature you want to drop:</span>
    df.drop(columns = max_p_value, inplace = <span style="color: #D0372D;">True</span>)
    <span style="color: #0000FF;">return</span> df
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #BA36A5;">y</span> = datosModelo3[<span style="color: #008000;">'dataLog'</span>]
<span style="color: #BA36A5;">X</span> = datosModelo3.iloc[:,1:-1]
<span style="color: #BA36A5;">significacion</span> = 0.05
<span style="color: #BA36A5;">insignificant_feature</span> = <span style="color: #D0372D;">True</span>
<span style="color: #0000FF;">while</span> insignificant_feature:
        <span style="color: #BA36A5;">model4</span> = sm.OLS(y, X)
        <span style="color: #BA36A5;">results4</span> = model4.fit()
        <span style="color: #BA36A5;">significant</span> = [p_value &lt; significacion <span style="color: #0000FF;">for</span> p_value <span style="color: #0000FF;">in</span> results4.pvalues]
        <span style="color: #0000FF;">if</span> <span style="color: #006FE0;">all</span>(significant):
            <span style="color: #BA36A5;">insignificant_feature</span> = <span style="color: #D0372D;">False</span>
        <span style="color: #0000FF;">else</span>:
            <span style="color: #0000FF;">if</span> X.shape[1] == 1:  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">if there's only one insignificant variable left</span>
                <span style="color: #006FE0;">print</span>(<span style="color: #008000;">'No significant features found'</span>)
                <span style="color: #BA36A5;">results4</span> = <span style="color: #D0372D;">None</span>
                <span style="color: #BA36A5;">insignificant_feature</span> = <span style="color: #D0372D;">False</span>
            <span style="color: #0000FF;">else</span>:            
                <span style="color: #BA36A5;">X</span> = remove_most_insignificant(X, results4)

<span style="color: #006FE0;">print</span>(results4.summary())
</pre>
</div>


<div>
<img src="./img/lecc02/resultsModel4.png" width="400" class="center"/>
</div>

<p>

</p>

<p>
Pero esta inferencia es incorrecta. Con auto-correlación la varianza
del estimador MCO es diferente (<b>la estimación por defecto de las
desviaciones típicas es incorrecta</b>)
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-orgf59aaa1" class="outline-2">
<h2 id="orgf59aaa1"><span class="section-number-2">2.</span> Perturbaciones no esféricas</h2>
<div class="outline-text-2" id="text-2">
<p>
Considere el modelo
\(\boldsymbol{y}=\boldsymbol{\mathsf{X}\beta}+\boldsymbol{U}.\;\) Bajo
los supuestos habituales
</p>

<p>
\[E(\boldsymbol{U}\mid\boldsymbol{\mathsf{X}})=\boldsymbol{0},\quad
Var(\boldsymbol{U}\mid\boldsymbol{\mathsf{X}})=\sigma^2\boldsymbol{\mathsf{I}}\quad
\text{y} \quad E(\boldsymbol{\mathsf{X'X}}) \text{ es invertible}\]
</p>

<p>
el estimador
\(\;\widehat{\boldsymbol{\beta}}=(\boldsymbol{\mathsf{X'X}})^{-1}\boldsymbol{\mathsf{X'}Y}\;\)
es insesgado y eficiente, con varianza
</p>

<p>
\[\;Var(\widehat{\boldsymbol{\beta}}\mid\boldsymbol{\mathsf{X}})=\sigma^2(\boldsymbol{\mathsf{X'X}})^{-1}\]
</p>

<p>

</p>

<p>
Pero si las perturbaciones \(\boldsymbol{U}\) del modelo son
heterocedásticas y/o autocorreladas
\[Var(\boldsymbol{U}\mid\boldsymbol{\mathsf{X}})=\boldsymbol{\Sigma}\ne\sigma^2\boldsymbol{\mathsf{I}}\]
entonces el estimador \(\widehat{\boldsymbol{\beta}}\), aunque
insesgado, ya no es eficiente; y su varianza es
</p>

<p>
\[Var(\widehat{\boldsymbol{\beta}}\mid\boldsymbol{\mathsf{X}})=Var(\widehat{\boldsymbol{\beta}}-\boldsymbol{\mathsf{I}}\boldsymbol{\beta}\mid\boldsymbol{\mathsf{X}})=
(\boldsymbol{\mathsf{X'X}})^{-1}\boldsymbol{\mathsf{X'}}
\boldsymbol{\Sigma}
\boldsymbol{\mathsf{X}}(\boldsymbol{\mathsf{X'X}})^{-1}.\]

</p>
</div>
<div id="outline-container-org87bd2b0" class="outline-3">
<h3 id="org87bd2b0"><span class="section-number-3">2.1.</span> Test de autocorrelación de Breusch y Godfrey</h3>
<div class="outline-text-3" id="text-2-1">
<p>
El tests Breusch-Godfrey (y el Durbin-Watson) contrastan la \(H_0\) de <i>no autocorrelación</i>.
</p>

<p>

Considere el <i>modelo de regresión lineal</i> 
</p>
\begin{equation}
\label{orgcf376f7}
Y_t = \beta_1+ \beta_2 X_{t,1} + \cdots +  \beta_k X_{t,k+1} + U_t 
\end{equation}

<p>

donde las perturbaciones \(\boldsymbol{U}\) quizá siguen un esquema
auto-regresivo \(AR(p)\):
</p>

<p>
\[U_t = \rho_1 U_{t-1} + \rho_2 U_{t-2}  + \cdots + \rho_p U_{t-p} + \varepsilon_t\]
</p>
<ul class="org-ul">
<li><b>Paso 1</b>. Obtener los errores \(\hat{\boldsymbol{e}}\) de ajuste MCO
de (\eqref{orgcf376f7}) (muestra de tamaño \(T\))</li>
<li><b>Paso 2</b>. Calcular el \(R^2\) de la <i>regresión auxiliar</i> de los
errores \(\hat{\boldsymbol{e}}\) sobre los regresores del modelo
original (\eqref{orgcf376f7}) y sobre los \(p\) primeros retardos
de \(\hat{\boldsymbol{e}}\).  \[\hat{e}_t = \alpha_0 + \alpha_1
  X_{t,1} + \cdots \alpha_k X_{t,k} + \rho_1 \hat{e}_{t-1} + \rho_2
  \hat{e}_{t-2} + \cdots + \rho_p \hat{e}_{t-p} + \varepsilon_t\]</li>
</ul>

<p>
Asintóticamente y bajo la \(H_0\) de <i>no autocorrelación</i>: \(\quad\rho_i = 0\text{ para todo }i\)
</p>

<p>
\[n R^2\,\sim\,\chi^2_p,\]
</p>

<p>

donde \(R^2\) es el coeficiente de determinación de la regresión
auxiliar y \(n=T-p\).

</p>

<p>
<b>El test de Durbin-Watson</b> contrasta la autocorrelación <span class="underline">de orden
uno</span>. Para muestras grandes, el test es aproximadamente igual a
\(2(1-{\hat {\rho }})\), donde \({\hat{\rho}}\) es la autocorrelación de
orden uno de los residuos. Por tanto, valores del test próximos a 2
indican no autocorrelación, valores próximos a 0 indican fuerte
autocorrelación positiva y valores próximos a 4 indican fuerte
autocorrelación negativa.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #0000FF;">import</span> statsmodels.stats.diagnostic <span style="color: #0000FF;">as</span> dg
<span style="color: #8D8D84;">#</span><span style="color: #8D8D84; font-style: italic;">perform Breusch-Godfrey t :results silentest of order p = 3</span>
<span style="color: #BA36A5;">arbg</span> = dg.acorr_breusch_godfrey(results4, nlags=3, store=<span style="color: #D0372D;">True</span>)
arbg[:1]
repr_png(arbg[-1].resols.summary().as_latex(), <span style="color: #008000;">"./img/lecc02/resultsBreusch-Godfrey.png"</span>) 
</pre>
</div>

<ul class="org-ul">
<li>Valor del estadístico: \(\quad \qquad\) (p-valor: \(\; 1.55e-13\))</li>
<li>\(x_{12}\) corresponde al primer retardo en la regresión auxiliar y es muy significativo</li>
</ul>

<div>
<img src="./img/lecc02/resultsBreusch-Godfrey.png" width="450" class="center"/>
</div>
</div>
</div>
<div id="outline-container-org61a4266" class="outline-3">
<h3 id="org61a4266"><span class="section-number-3">2.2.</span> Errores estándar robustos</h3>
<div class="outline-text-3" id="text-2-2">
<p>
Un procedimiento adecuado en presencia de autocorrelación y muestras
grandes consiste en usar errores estándar <i>robustos</i> (<b>HAC</b> -
heteroscedasticity and autocorrelation robust covariance matrix) al
realizar inferencia con la estimación de los parámetros.
</p>

<ol class="org-ol">
<li>las estimaciones serán insesgadas, consistentes pero ineficientes,</li>

<li>los residuos son los mismos y, por tanto, estarán autocorrelados, aunque</li>

<li>la inferencia a partir de errores estándar robustos será válida</li>
</ol>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #BA36A5;">y</span> = datosModelo3[<span style="color: #008000;">'dataLog'</span>]
<span style="color: #BA36A5;">X</span> = datosModelo3.iloc[:,1:-1]
<span style="color: #BA36A5;">model5</span> = sm.OLS(y, X)
<span style="color: #BA36A5;">results5</span> = model5.fit()
<span style="color: #006FE0;">print</span>(results5.get_robustcov_results(cov_type=<span style="color: #008000;">'HAC'</span>, maxlags=3, use_correction=<span style="color: #D0372D;">True</span>).summary())
</pre>
</div>


<div class="org-src-container">
<pre class="src src-jupyter-python">repr_png(results5.get_robustcov_results(cov_type=<span style="color: #008000;">'HAC'</span>, maxlags=3, use_correction=<span style="color: #D0372D;">True</span>).summary().as_latex(), <span style="color: #008000;">"./img/lecc02/resultsModel5.png"</span>)
</pre>
</div>

<ul class="org-ul">
<li><b>Covariance type</b>: HAC (heteroscedasticity and autocorrelation robust covariance matrix)</li>
</ul>
<div>
<img src="./img/lecc02/resultsModel5.png" width="400" class="center"/>
</div>

<p>
Ahora, y empleando errores estándar robustos (HAC), podemos reducir el
modelo de manera más cuidadosa usando desviaciones típicas
robustas. El modelo reducido es&#x2026;
</p>


<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #BA36A5;">y</span> = datosModelo3[<span style="color: #008000;">'dataLog'</span>]
<span style="color: #BA36A5;">X</span> = datosModelo3.iloc[:,1:-1]

<span style="color: #BA36A5;">significacion</span> = 0.05

<span style="color: #BA36A5;">insignificant_feature</span> = <span style="color: #D0372D;">True</span>
<span style="color: #0000FF;">while</span> insignificant_feature:
        <span style="color: #BA36A5;">results6</span>      = sm.OLS(y, X).fit()
        <span style="color: #BA36A5;">robustResults</span> = results6.get_robustcov_results(cov_type=<span style="color: #008000;">'HAC'</span>, maxlags=3, use_correction=<span style="color: #D0372D;">True</span>)
        <span style="color: #BA36A5;">robustPvalues</span> = pd.Series(index=results6.pvalues.index, data=robustResults.pvalues)

        <span style="color: #BA36A5;">significant</span> = [p_value &lt; significacion <span style="color: #0000FF;">for</span> p_value <span style="color: #0000FF;">in</span> robustPvalues]

        
        <span style="color: #0000FF;">if</span> <span style="color: #006FE0;">all</span>(significant):
            <span style="color: #BA36A5;">insignificant_feature</span> = <span style="color: #D0372D;">False</span>
        <span style="color: #0000FF;">else</span>:
            <span style="color: #0000FF;">if</span> X.shape[1] == 1:  <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">if there's only one insignificant variable left</span>
                <span style="color: #006FE0;">print</span>(<span style="color: #008000;">'No significant features found'</span>)
                <span style="color: #BA36A5;">results6</span> = <span style="color: #D0372D;">None</span>
                <span style="color: #BA36A5;">insignificant_feature</span> = <span style="color: #D0372D;">False</span>
            <span style="color: #0000FF;">else</span>:            
                <span style="color: #BA36A5;">X</span> = remove_most_insignificant(X, results6)
<span style="color: #006FE0;">print</span>(robustResults.summary())
repr_png(robustResults.summary().as_latex(), <span style="color: #008000;">"./img/lecc02/resultsModel6.png"</span>) 
</pre>
</div>

<div>
<img src="./img/lecc02/resultsModel6.png" width="400" class="center"/>
</div>
<ul class="org-ul">
<li>Nótese que ahora (HAC) se aprecia que enero y octubre son significativos al 5%</li>
<li>Pero la estimación MCO no es eficiente en presencia de auto-correlación</li>
</ul>
</div>
</div>
<div id="outline-container-orgec246c8" class="outline-3">
<h3 id="orgec246c8"><span class="section-number-3">2.3.</span> Modelo del error</h3>
<div class="outline-text-3" id="text-2-3">
<p>
En el modelo
\(\boldsymbol{y}=\boldsymbol{\mathsf{X}\beta}+\boldsymbol{U},\;\) si las
perturbaciones presentan heterocedasticidad y/o auto-correlación, y
por tanto
\[Var(\boldsymbol{U}\mid\boldsymbol{\mathsf{X}})=\boldsymbol{\Sigma}\ne\sigma^2\boldsymbol{\mathsf{I}},\]
el Teorema de Gauss-Markov ya no es válido, ya que es posible explotar
la estructura de la matriz \(\boldsymbol{\Sigma}\) para minimizar la
varianza del estimador.
</p>

<p>
En particular, el estimador lineal de mínima varianza es el estimador
MCG (mínimos cuadrados generalizados)
</p>

<p>
\[\;\widehat{\boldsymbol{\beta}}=(\boldsymbol{\mathsf{X'}}\boldsymbol{\mathsf{\Sigma}}^{-1}\boldsymbol{\mathsf{X}})^{-1}\boldsymbol{\mathsf{X'}}\boldsymbol{\mathsf{\Sigma}}^{-1}\boldsymbol{y}\;\]
</p>

<p>
El problema es que, en general, la matriz \(\boldsymbol{\Sigma}\) es
desconocida.
</p>

<p>
Una solución es aplicar un procedimiento iterativo en el que se estima
la matriz \(\boldsymbol{\Sigma}\) empleando los errores del ajuste de
una primera regresión. Con dicha matriz
\(\widehat{\boldsymbol{\Sigma}}\) se re-estima el modelo por MCG&#x2026; con
los nuevos errores se re-estima \(\boldsymbol{\Sigma}\)&#x2026; y vuelta a
empezar&#x2026;
</p>

<p>
El algoritmo se detiene cuando las estimaciones convergen a valores
estables.
</p>

<p>
Cuando realizamos el Test de Breusch-Godfrey vimos que en la regresión
auxiliar el primer retardo de los errores era significativo. Por
tanto, vamos a indicar que las perturbaciones siguen un proceso AR(1).
El decir, vamos a estimar el modelo
</p>

<p>
\[\ln{y_t}=\underbrace{\beta_1+\beta_2\cdot t+\beta_3\cdot t^2}_{\text{tendencia}} + \underbrace{\alpha_1 S_{t1} + \alpha_3 S_{t3} + \cdots + \alpha_11 S_{t11}}_{\text{comp. estacional}} + \epsilon_t\]
</p>

<p>
donde las perturbaciones \(\boldsymbol{\epsilon}=\{\epsilon_t\}\) siguen
el modelo
</p>

<p>
\[\epsilon_t = \rho_1 \epsilon_{t-1} + e_t\]
</p>

<p>
(<i>en este caso la estimación (<b>GLSAR</b>) converge en 7 iteraciones</i>)
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #BA36A5;">model</span> = sm.GLSAR(y, X, rho=1) <span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">:results silent rho=1 indica autocorrelaci&#243;n de orden uno</span>
<span style="color: #0000FF;">for</span> i <span style="color: #0000FF;">in</span> <span style="color: #006FE0;">range</span>(7):
    <span style="color: #BA36A5;">results</span> = model.fit()
    <span style="color: #006FE0;">print</span>(<span style="color: #008000;">"AR coefficients: {0}"</span>.<span style="color: #006FE0;">format</span>(model.rho))
    <span style="color: #BA36A5;">rho</span>, <span style="color: #BA36A5;">sigma</span> = sm.regression.yule_walker(results.resid,
                                           order=model.order)
    <span style="color: #BA36A5;">model</span> = sm.GLSAR(y, X, rho)
</pre>
</div>


<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #006FE0;">print</span>(results.summary())
</pre>
</div>

<div>
<img src="./img/lecc02/resultsModel7.png" width="600" class="center"/>
</div>




<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #8D8D84;"># </span><span style="color: #8D8D84; font-style: italic;">este c&#243;digo realiza las mismas iteraciones que bloque de c&#243;digo de m&#225;s arriba</span>
<span style="color: #BA36A5;">model2</span> = sm.GLSAR(y, X, rho=1)
<span style="color: #BA36A5;">res</span> = model2.iterative_fit(maxiter=7)
model2.rho
<span style="color: #006FE0;">print</span>(model2.fit().summary())
</pre>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Marcos Bujosa</p>
<p class="date">Created: 2024-09-30 lun 16:30</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
