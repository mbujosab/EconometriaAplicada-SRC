{"cells":[{"cell_type":"markdown","id":"c683993c-c102-488f-8c06-d373c1793655","metadata":{},"source":"Econometría Aplicada. Lección 5\n===============================\n\n**Author:** Marcos Bujosa\n\n"},{"cell_type":"markdown","id":"07084041-a6c9-4e2e-841b-638788b87768","metadata":{},"source":["<div class=\"abstract\" id=\"org2629699\">\n<p>\nEsta lección veremos las dificultades que ocasiona la correlación\nserial y algunos tipos de procesos débilmente estacionarios que nos\npermitirán lidiar con ella.\n</p>\n\n</div>\n\n-   [lección en html](https://mbujosab.github.io/EconometriaAplicada-SRC/Lecc05.html)\n-   [lección en mybinder](https://mybinder.org/v2/gh/mbujosab/EconometriaAplicada-SRC/HEAD?labpath=Lecc05.ipynb)\n\n"]},{"cell_type":"markdown","id":"8c367b70-812f-4237-8a28-53d8872dbb29","metadata":{"slideshow":{"slide_type":"notes"}},"source":["#### Carga de algunas librerías de R\n\n"]},{"cell_type":"markdown","id":"9327d804-4e51-4603-877d-d63eb5bd9921","metadata":{"slideshow":{"slide_type":"notes"}},"source":["Primero cargamos la librería `tfarima` (Repositorio Cran:\n[https://cran.r-project.org/web/packages/tfarima/index.html](https://cran.r-project.org/web/packages/tfarima/index.html);\nrepositorio GitHub: [https://github.com/gallegoj/tfarima](https://github.com/gallegoj/tfarima))\n\n"]},{"cell_type":"code","execution_count":1,"id":"410f23dd-28f7-49e9-8c86-020a696ecfd4","metadata":{"slideshow":{"slide_type":"notes"}},"outputs":[],"source":["library(tfarima)      # librería de José Luis Gallego para Time Series\nlibrary(readr)        # para leer ficheros CSV\nlibrary(ggplot2)      # para el scatterplot (alternaticamente library(tidyverse))\nlibrary(ggfortify)    # para pintar series temporales\nlibrary(jtools)       # para representación resultados estimación\nlibrary(zoo)          # para generar objetos ts (time series)"]},{"cell_type":"markdown","id":"90c87b9b-c33d-4ba0-b2df-50209701bb51","metadata":{"slideshow":{"slide_type":"notes"}},"source":["y además fijamos los parámetros por defecto para las figuras en `png`\ndel notebook\n\n"]},{"cell_type":"code","execution_count":1,"id":"4fb2c5f5-a9f8-4a32-a6de-5f24c1f7bc9d","metadata":{"slideshow":{"slide_type":"notes"}},"outputs":[],"source":["# fijamos el tamaño de las figuras que se generan en el notebook\noptions(repr.plot.width = 12, repr.plot.height = 4, repr.plot.res = 200)"]},{"cell_type":"markdown","id":"8b623014-26bb-4ce1-ba98-e60df1816e7c","metadata":{"slideshow":{"slide_type":"slide"}},"source":["## Series temporales vs datos de sección cruzada\n\n"]},{"cell_type":"markdown","id":"f40e22d4-d784-4292-bdb3-41de08391c72","metadata":{},"source":["Corresponden a observaciones de un mismo objeto a lo largo del\ntiempo. El índice indica el instante de cada medición. *El orden\ncronológico puede ser crucial* al modelar los datos.\n\n-   El motivo es que frecuentemente el valor medido en un instante de\n    tiempo está relacionado con otras mediciones próximas en el tiempo\n    (*correlación serial*).\n\n-   Si es así, ya no deberíamos asumir que las variables aleatorias del\n    proceso estocástico subyacente, $\\boldsymbol{X}=(X_t\\mid\n      t\\in\\mathbb{Z})$, son independientes entre sí.\n\nEsto tiene importantes implicaciones en las técnicas de análisis y\nlos modelos a utilizar.\n\n"]},{"cell_type":"markdown","id":"40e4391d-5f30-4f99-a422-8d897cc48b02","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["##### Población en Australia\n\n"]},{"cell_type":"code","execution_count":1,"id":"a3449327-f82d-422e-9f03-8ed1ef4655fd","metadata":{"slideshow":{"slide_type":"notes"}},"outputs":[],"source":["PoblacionAustralia_ts = as.ts( read.zoo('datos/PoblacionAustralia.csv', \n                                        header=TRUE,\n                                        index.column = 1, \n                                        sep=\",\", \n                                        FUN = as.yearmon))\np <- autoplot(PoblacionAustralia_ts)\np <- p + labs(y = \"Habitantes\", x = \"Años\") + ggtitle(\"Población australiana (datos anuales)\")\np <- p + scale_x_continuous(breaks = scales::pretty_breaks(n = 20))\np"]},{"cell_type":"markdown","id":"27cfd274-10c5-4815-a25b-223f8208869f","metadata":{},"source":["![img](./img/lecc05/PoblacionAustralia.png)\n\n"]},{"cell_type":"markdown","id":"684c91ea-301b-4512-8e12-3a50bc1f37ee","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["##### PIB UEM\n\n"]},{"cell_type":"code","execution_count":1,"id":"0f105329-f6de-4a19-b86a-d2be9b03aebd","metadata":{"slideshow":{"slide_type":"notes"}},"outputs":[],"source":["PIB_UEM_df <- read_csv(\"datos/PIB_UEM.csv\",\n                     show_col_types = FALSE)\nfmt <- \"%YQ%q\"\nPIB_UEM_df$Time <- as.yearqtr(PIB_UEM_df$obs, format = fmt)\n# head(PIB_UEM_df,3)\nP <- ggplot(PIB_UEM_df, aes(Time, PIB))\nP <- P + geom_point() + geom_line()\nP <- P + scale_x_continuous(breaks = scales::pretty_breaks(n = 15))\nP <- P + labs(y = \"Miles de millones de euros\", x = \"Años\") + ggtitle(\"PIB UEM a precios corrientes (datos trimestrales). Fuente Banco de España\")\nP"]},{"cell_type":"markdown","id":"4dfc4dda-d176-4358-ab9f-c88c28878491","metadata":{},"source":["![img](./img/lecc05/PIB_UEM.png)\n\n"]},{"cell_type":"markdown","id":"8d2faccb-b411-4d64-bced-405775d904c2","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["##### Temperatura media en el Parque del Retiro. Madrid\n\n"]},{"cell_type":"code","execution_count":1,"id":"834ae167-a6cd-44a2-b10b-cebb1f451659","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["TemperaturaRetiro_df <- read_csv(\"datos/Retiro.txt\", show_col_types = FALSE)\n# Añadimos fechas\nTemperaturaRetiro_df$Time <- as.yearmon(1985 + seq(0, nrow(TemperaturaRetiro_df)-1)/12)\n\nP <- ggplot(TemperaturaRetiro_df, aes(Time, TemperaturaMedia))\nP <- P + geom_line() # + geom_point() \nP <- P + scale_x_continuous(breaks = scales::pretty_breaks(n = 25))\nP <- P + labs(y = \"Grados Celsius\", x = \"Años\") + ggtitle(\"Temperatura media mensual en el Parque del Retiro. Fuente: Comunidad de Madrid\")\nP"]},{"cell_type":"markdown","id":"68429353-dc84-4fb7-b3cd-bec14f97f25e","metadata":{},"source":["![img](./img/lecc05/TemperaturaReriro.png)\n\n"]},{"cell_type":"markdown","id":"24a8072e-8ba5-4398-a496-f1d0d418cb08","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["##### Rendimiento porcentual diario del IBEX 35 (std)\n\n"]},{"cell_type":"code","execution_count":1,"id":"91fe6692-aec0-42de-8e50-a6a03379df4d","metadata":{"slideshow":{"slide_type":"notes"}},"outputs":[],"source":["IBEX35_ts = as.ts( read.csv.zoo(\"datos/IBEX35.csv\", \n                                strip.white = TRUE))\nP <- autoplot(IBEX35_ts) + scale_y_continuous(breaks = scales::pretty_breaks(n = 12))\np <- P + labs(y = \"Desviaciones tipicas\", x = \"Días\") + ggtitle(\"Rendimiento porcentual diario del IBEX 35 (std.). Fuente: Archivo Prof. Miguel Jerez\")\np"]},{"cell_type":"markdown","id":"77333563-f252-447d-bfed-81b3131d0664","metadata":{},"source":["![img](./img/lecc05/IBEX35.png)\n\n-   Datos centrados y estandarizados, i.e. el eje vertical está en desviaciones típicas.\n-   Los *volatility clustering* son característicos de series financieras de alta frecuencia.\n\n"]},{"cell_type":"markdown","id":"40e81a1e-7baa-4918-a30b-21288e3c6df0","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["##### Producción de cemento\n\n"]},{"cell_type":"code","execution_count":1,"id":"381b3e6b-04d3-41d8-9d1e-65ab6e618c16","metadata":{"slideshow":{"slide_type":"notes"}},"outputs":[],"source":["ProduccionCemento_df <- read_csv(\"datos/ProduccionCemento.csv\",\n                     show_col_types = FALSE)\nfmt <- \"%YM%m\"\nProduccionCemento_df$Time <- as.yearmon(ProduccionCemento_df$obs, format = fmt)\n# head(ProduccionCemento_df,3)\nP <- ggplot(ProduccionCemento_df, aes(Time, ProduccionCemento))\nP <- P + geom_line() # + geom_point() \nP <- P + scale_x_continuous(breaks = scales::pretty_breaks(n = 25))\nP <- P + labs(y = \"Miles de Toneladas métricas\", x = \"Años\") + ggtitle(\"Produccion de cemento (Datos mensuales). Fuente Banco de España\")\nP"]},{"cell_type":"markdown","id":"d643bff5-e538-4e39-aacd-f5205fa8d0bf","metadata":{},"source":["![img](./img/lecc05/ProduccionCemento.png)\n\n"]},{"cell_type":"markdown","id":"abae2e39-5800-4518-b83d-9d164848f7b4","metadata":{"slideshow":{"slide_type":"slide"}},"source":["### Correlación serial vs muestreo aleatorio simple\n\n"]},{"cell_type":"markdown","id":"a4de06eb-4767-4e0e-a62b-65515b433c81","metadata":{},"source":["Con datos de\n\n-   **sección cruzada:** solemos asumir que el muestreo es aleatorio\n    simple\n    -   i.e., los datos son realizaciones de variables aleatorias i.i.d.\n\n-   **series temporales:** dicha asunción resulta generalmente errónea\n    \n    -   con frecuencia el nivel esperado (o la volatilidad) parece cambiar con $t$\n    -   con frecuencia hay dependencia temporal (correlación serial).\n    \n    **Ejemplo**: no parece aceptable asumir que $ProdCemento_{1960M01}$ se\n    distribuye igual que $ProdCemento_{2000M04}$ (ni que sea\n    independiente de $ProdCemento_{1959M01}$).\n\nVeamos por qué esto genera dificultades&#x2026;\n\n"]},{"cell_type":"markdown","id":"08c950e0-9d58-44b2-9b4d-680ecd5829c6","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["Consideremos el proceso estocástico $$\\boldsymbol{X}=(X_t \\mid\nt=0,\\pm1,\\pm2,\\ldots).$$ Caracterizar su distribución conjunta (todos\nlos momentos) es demasiado ambicioso.\n\n"]},{"cell_type":"markdown","id":"a4804206-aa26-47a0-8356-a5f18819549f","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Así que, tentativamente, vamos a fijarnos *solo* en los dos primeros\nmomentos:\n\n$$E(X_t)={\\color{blue}{ \\mu_t}}\\quad\\text{ y }\\quad\nCov(X_t,X_k)=E\\big[(X_t-\\mu_t)(X_k-\\mu_k)\\big]={\\color{blue}{\\lambda_{t,k}}};\\quad t,k\\in\\mathbb{Z}$$\n\n(si $\\;k=t\\;$ entonces $\\;\\lambda_{t,t}=Var(X_t)=\\sigma^2_t$).\n\nSi el proceso $\\boldsymbol{X}$ fuera gaussiano, conocer estos\n*parámetros* bastaría para caracterizar la distribución conjunta. Pero\naún así&#x2026;\n\n"]},{"cell_type":"markdown","id":"69ca2fb4-f6b9-44a8-8179-364fccfdae4a","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["-   necesitaríamos para cada $X_t$ una muestra suficiente para estimar los parámetros \n    -   pero en una serie temporal tenemos una sola realización de cada $X_t$.\n\n-   Además&#x2026; para cada variable aleatoria $X_t$ hay infinitos parámetros.\n\n"]},{"cell_type":"markdown","id":"3c54b734-86dc-4ddb-a971-62118f46af04","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["### Tipos de procesos estocásticos que simplifican el escenario\n\n"]},{"cell_type":"markdown","id":"43886096-353e-4bbd-afe4-b6926cb24baa","metadata":{},"source":["-   Si es [débilmente estacionario](./Lecc01.slides.html#/3/1) se reduce drásticamente el número de\n    parámetros:\n    \n    \\begin{eqnarray}\n    E(X_t)  & = \\mu \\\\\n    Cov(X_t,X_{t-k}) & = \\gamma_k\n    \\end{eqnarray}\n-   Si además es i.i.d. podemos interpretar la serie temporal como una\n    realización de un muestreo aleatorio simple.\n\n"]},{"cell_type":"markdown","id":"1278d819-cd23-4ae7-9bd2-5d840723ebbc","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["El desafío para el analista es (y nótese el abuso de lenguaje)\n\n-   **primero:** transformar los datos para lograr que sean \"***estacionarios***\".\n    -   (Algo vimos en la lección 1))\n-   **después:** transformar los datos estacionarios en una secuencia de\n    \"**datos *i.i.d***\" \n    -   (Aún no lo hemos visto)\n\nTodo este proceso constituye la especificación y ajuste de un modelo a\nla serie temporal.\n\n"]},{"cell_type":"markdown","id":"c9cf2957-bd2a-436c-ac10-952bd6236797","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Antes de atacar los temas de especificación y ajuste de modelos,\ndebemos estudiar un poco los procesos estocásticos débilmente\nestacionarios que vamos a utilizar.\n\n"]},{"cell_type":"markdown","id":"823c4298-50cd-4889-9fab-b56604fbde46","metadata":{"slideshow":{"slide_type":"slide"}},"source":["## Procesos estocásticos de segundo orden\n\n"]},{"cell_type":"markdown","id":"c9b35663-7a51-47a5-a48c-ef7afa8610c7","metadata":{},"source":["El ambiente natural para estudiar las propiedades de segundo orden de\nuna colección de variables aleatorias es el espacio de variables\naleatorias $X$ definidas en un espacio de probabilidad tales que\n$$E(X)=0 \\quad\\text{y}\\quad E(X^2)<\\infty$$ donde $E$ es el operador\nesperanza. Denotaremos este espacio con $H$.\n\n"]},{"cell_type":"markdown","id":"fdee926a-ad92-4b66-bc0c-b165f0e04115","metadata":{"slideshow":{"slide_type":"notes"}},"source":["### Un poco de geometría\n\n"]},{"cell_type":"markdown","id":"7bf1099f-7793-46f2-8b72-bf7061cd8208","metadata":{"slideshow":{"slide_type":"notes"}},"source":["El espacio, dotado de producto escalar y norma $$\\langle X \\mid Y\n\\rangle=E(XY),\\qquad \\lVert X \\rVert= \\sqrt{E(X^2)},\\qquad X,Y \\in\nH,$$ es un espacio de Hilbert,\n\nNótese que como las variables de $H$ tienen esperanza cero, el\nproducto escalar entre $X,Y\\in H$ también es $$\\langle X \\mid Y\n\\rangle=Cov(X,Y).$$ Por tanto, en este espacio $H$ la noción\ngeométrica de ortogonalidad coincide con la noción estadística de *no\ncorrelación*. Por tanto, en este contexto los términos producto\nescalar, covarianza y esperanza del producto serán intercambiables.\n\n"]},{"cell_type":"markdown","id":"014b22c8-7bfc-445c-be67-2ea9b3c3f3c3","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Una colección de variables aleatorias pertenecientes a $H$\n$$\\boldsymbol{X}=(X_t\\mid t\\in\\mathbb{Z}) \\;\\text{ con }\\; X_t\\in H$$\nse denomina *proceso estocástico de segundo orden*.\n\n"]},{"cell_type":"markdown","id":"f4f4519a-7680-4c62-8b23-4446c8fcf49a","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Si $\\boldsymbol{Y}=(Y_t\\mid t\\in\\mathbb{Z})$ es tal que\n$E(Y_t)=\\mu\\ne0$, entonces $\\boldsymbol{Y}$ no es de segundo orden.\n\nPero basta restar $\\mu$ de cada $Y_t$ para tener un proceso\n$(\\boldsymbol{Y}-\\boldsymbol{\\mu})$ de segundo orden.\n\n*Por ello siempre asumiremos* (sin pérdida de generalidad) *que las\nvariables aleatorias de los procesos estocásticos de esta lección* (y\nla siguiente) *tienen esperanza cero*.\n\n"]},{"cell_type":"markdown","id":"e0cd1861-853f-448a-9a0d-f94a5a32ad68","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["### Función de covarianzas\n\n"]},{"cell_type":"markdown","id":"22eb1a22-206c-432c-bf8c-ff21f3fc1048","metadata":{},"source":["La *función de covarianzas* de un proceso estocástico $\\boldsymbol{X}$\nsegundo orden es $$\\boldsymbol{\\gamma}=(\\gamma_{s,t}\\mid\ns,t\\in\\mathbb{Z})$$ donde $\\gamma_{s,t}=Cov(X_s,X_t)\\quad\ns,t\\in\\mathbb{Z}$.\n\nAsí, para cada par $(s,t)$, la covarianza $\\gamma_{s,t}$ mide la\ndependencia lineal entre $X_s$ y $X_t$.\n\n"]},{"cell_type":"markdown","id":"32f742ee-2cb3-4ecb-944b-e39ef9525cad","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Esta función $\\boldsymbol{\\gamma}$ es demasiado general, por eso nos\nrestringiremos a la subclase de procesos estocásticos *débilmente\nestacionarios*; pues simplifican enormemente la *función de\ncovarianzas* $\\boldsymbol{\\gamma}$.\n\n"]},{"cell_type":"markdown","id":"ce4b1f94-d2a4-4a24-b0fb-6fa1023729d6","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["### Proceso estocástico (débilmente) estacionario y su ACF\n\n"]},{"cell_type":"markdown","id":"6c24e418-e309-4215-97b0-8c78c87d98ea","metadata":{},"source":["Un proceso estocástico de segundo orden $\\boldsymbol{X}$ se dice que\nes *débilmente estacionario* si la covarianza entre $X_s$ y $X_t$\nsolo depende de la diferencia $s-t$ para todo $s,t\\in\\mathbb{Z}$.\n\nEn tal caso se denomina *función de <u>auto</u>-covarianzas* de\n$\\boldsymbol{X}$ a la secuencia\n$$\\boldsymbol{\\gamma}(z)\\;=\\;(\\gamma_k\\mid\nk\\in\\mathbb{Z})\\;=\\;\\sum_{-\\infty}^{\\infty} \\gamma_k z^k$$ donde\n$\\;\\gamma_k=Cov(X_{t+k}, X_{t})\\;$ para $k\\in\\mathbb{Z}$.\n\n**Propiedades** de la función de autocovarianzas $\\boldsymbol{\\gamma}$ (ACF):\n\n-   $\\gamma_0\\geq0$\n-   $\\boldsymbol{\\gamma}$ <u>es definida positiva</u>; y por tanto,\n    -   $\\boldsymbol{\\gamma}$ es simétrica: $\\gamma_k=\\gamma_{-k}$\n    -   $\\boldsymbol{\\gamma}$ es acotada: $|\\gamma_k|\\leq\\gamma_0$\n\nllamamos *función de autocorrelación* (ACF) a la\nsecuencia:\n$\\;\\boldsymbol{\\rho}=\\frac{1}{\\gamma_0}(\\boldsymbol{\\gamma})\n=\\sum\\limits_{k\\in\\mathbb{Z}}\\frac{\\gamma_k}{\\gamma_0}z^k$.\n\n"]},{"cell_type":"markdown","id":"852a3199-777c-4feb-afc2-1a8c402ec406","metadata":{"slideshow":{"slide_type":"slide"}},"source":["## Ejemplos de procesos (débilmente) estacionarios\n\n"]},{"cell_type":"markdown","id":"a41b426a-3ec4-4965-98e1-e886572712ec","metadata":{},"source":["### Proceso de ruido blanco\n\n"]},{"cell_type":"markdown","id":"5492f166-dee6-4ab2-93a4-621985b5c951","metadata":{},"source":["Una secuencia $\\boldsymbol{U}=(U_t\\mid t\\in\\mathbb{Z})$ de variables\naleatorias incorreladas y tales que $$E(U_t)=0\\quad\\text{ y }\\quad\nVar(U_t)=E(U_t^2)=\\sigma^2$$ para $\\;t\\in\\mathbb{Z}\\;$ y\n$\\;0<\\sigma^2<\\infty\\;$ se llama *proceso de ruido blanco*.\n$\\quad\\boldsymbol{U}\\sim WN(0,\\sigma^2)$.\n\n"]},{"cell_type":"markdown","id":"e4dacf98-af7f-4068-bd92-364422ea84ed","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Al ser variables aleatorias incorreladas, su función de\nautocovarianzas es $$\\boldsymbol{\\gamma}(z)\\;=\\;\\sigma^2\nz^0\\;=\\;(\\ldots,0,0,\\sigma^2,0,0,\\ldots)$$\n\n-   Es el proceso estacionario (no trivial) más sencillo.\n-   Este proceso es el pilar sobre el que definiremos el resto de\n    ejemplos.\n\n"]},{"cell_type":"markdown","id":"bfd6d984-84aa-438c-b1b4-e2a5ceac9d30","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["### Procesos lineales\n\n"]},{"cell_type":"markdown","id":"aa42faad-e624-4134-8586-b32b100597ee","metadata":{},"source":["Sea $\\boldsymbol{U}\\sim WN(0,\\sigma^2)$ y sea $\\boldsymbol{b}\\in\n\\ell^2$; una secuencia de <u>cuadrado sumable</u>\n$\\;\\sum\\limits_{j\\in\\mathbb{Z}}{b}_j^2<\\infty$.\n\nDenominamos *proceso lineal* al proceso estocástico\n$\\boldsymbol{X}=\\boldsymbol{b}*\\boldsymbol{U}$ cuyos elementos son $$X_t\n\\;=\\;(\\boldsymbol{b}*\\boldsymbol{U})_t\n\\;=\\;\\boldsymbol{b}(B)U_t \\;=\\;\\sum_{j=-\\infty}^\\infty {b}_j\nU_{t-j};\\qquad t\\in\\mathbb{Z}.$$\n\n"]},{"cell_type":"markdown","id":"0c5c4bfa-594f-4491-8f69-cb7fd2f6df0f","metadata":{"slideshow":{"slide_type":"notes"}},"source":["$\\boldsymbol{b}(B)$ se denomina *función de transferencia* del\nfiltro lineal que relaciona $X_t$ con $U_t$.\n\n"]},{"cell_type":"markdown","id":"fbad5aff-ba60-4102-9c19-b3c5e144817d","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["El proceso lineal es *\\`\\`causal''* si además $\\boldsymbol{b}$ es\nuna <u>serie formal</u> (i.e.,\n$cogrado(\\boldsymbol{b})\\geq{\\color{blue}{0}}$)\n$$X_t=\\sum_{j=0}^\\infty {b}_j U_{t-j};\\qquad\nt\\in\\mathbb{Z}$$ $\\;$ (pues cada $X_t$ es una suma de variables \"*del\npresente y pasado*\").\n\n"]},{"cell_type":"markdown","id":"72d28b80-61a1-4d74-a128-868cc58318de","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["La clase de procesos lineales incluye muchas e importantes subclases\nde procesos, algunas de las cuales son objeto principal de estudio de\neste curso.\n\n"]},{"cell_type":"markdown","id":"5a3a8a8d-f901-4a6e-9994-2be4c5311cfc","metadata":{"slideshow":{"slide_type":"slide"}},"source":["#### Media móvil infinita. MA($\\infty$)\n\n"]},{"cell_type":"markdown","id":"3938fae1-cc08-49b4-99cc-1b38ed36fc65","metadata":{},"source":["Sea $\\;\\boldsymbol{U}\\sim WN(0,\\sigma^2)\\;$ y sea\n$\\;\\boldsymbol{\\psi}\\in \\ell^2\\;$ una serie formal con <u>infinitos\ntérminos NO nulos</u>; entonces el proceso estocástico\n$\\boldsymbol{\\psi}*\\boldsymbol{U}$, cuyos elementos son $$X_t\n\\;=\\;(\\boldsymbol{\\psi}*\\boldsymbol{U})_t\n\\;=\\;\\boldsymbol{\\psi}(B)U_t \\;=\\;\\sum_{j=0}^\\infty \\psi_j\nU_{t-j};\\qquad t\\in\\mathbb{Z}$$ se denomina proceso de *media móvil\ninfinita* MA($\\infty$).\n\n"]},{"cell_type":"markdown","id":"a8ae4ddf-1b34-4aa6-856e-fe4f588ee967","metadata":{"slideshow":{"slide_type":"slide"}},"source":["Algunas clases de procesos lineales tienen una representación\nparsimoniosa, pues basta un número finito de parámetros para\nrepresentarlos completamente. Por ejemplo, cuando\n$\\boldsymbol{\\psi}$ tiene un número finito de términos no nulos&#x2026;\n\n"]},{"cell_type":"markdown","id":"1d93fcf1-994a-4032-b9af-f4715a6fe4c5","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["#### Proceso de media móvil de orden $q$. MA($q$)\n\n"]},{"cell_type":"markdown","id":"be1f3c98-46cd-4f76-afec-64ad5db85c44","metadata":{},"source":["Sea $\\;\\boldsymbol{U}\\sim WN(0,\\sigma^2)\\;$ y sea\n$\\;\\boldsymbol{\\theta}\\;$ un <u>polinomio de grado $q$</u> con\n${\\color{#008000}{\\theta_{0}=1}}$; entonces el proceso estocástico\n$\\boldsymbol{\\theta}*\\boldsymbol{U}$, cuyos elementos son $$X_t\n\\;=\\;(\\boldsymbol{\\theta}*\\boldsymbol{U})_t\n\\;=\\;\\boldsymbol{\\theta}(B)U_t \\;=\\;\\sum_{j=0}^q\\theta_j\nU_{t-j};\\qquad t\\in\\mathbb{Z}$$ se denomina proceso de *media móvil*\nMA($q$).\n\n"]},{"cell_type":"markdown","id":"c585cc86-9e5f-4428-9ae3-9e9451efd885","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Es decir:\n$$ X_t = U_t + \\theta_1 U_{t-1} + \\cdots + \\theta_q U_{t-q}.$$\n\n"]},{"cell_type":"markdown","id":"75d54ee8-5100-49be-926d-3a659e9aff74","metadata":{"slideshow":{"slide_type":"slide"}},"source":["Hay otros procesos lineales con representación parsimoniosa.\n\n"]},{"cell_type":"markdown","id":"c587d1aa-716f-4f63-8cbc-43845a048ac8","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["#### Proceso autorregresivo de orden $p$. AR($p$)\n\n"]},{"cell_type":"markdown","id":"439a323d-9e81-4e80-9a96-3feb5bd662ad","metadata":{},"source":["Sea $\\;\\boldsymbol{U}\\sim WN(0,\\sigma^2)\\;$, se denomina *proceso\nautorregresivo de orden $p$* a aquel proceso estocástico estacionario\n$\\;\\boldsymbol{X}\\;$ que es la solución de la siguiente ecuación en\ndiferencias $$\\boldsymbol{\\phi}*\\boldsymbol{X}=\\boldsymbol{U}$$ donde\n$\\;\\boldsymbol{\\phi}\\;$ un <u>polinomio de grado $p$</u> con ${\\color{#008000}{\\phi_{0}=1}}$;\n\n"]},{"cell_type":"markdown","id":"48080977-a685-4062-b78f-f2e45e220e91","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Por tanto, $$(\\boldsymbol{\\phi}*\\boldsymbol{X})_t=\n\\boldsymbol{\\phi}(\\mathsf{B})X_t= \\sum_{j=0}^p \\phi_j X_{t-j} = U_t.$$\n\n"]},{"cell_type":"markdown","id":"25f39c54-c44d-499a-abcf-36618b4eaf5f","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Es decir $\\boldsymbol{X}=(X_t\\mid t\\in\\mathbb{Z})$ es una solución de\nla siguiente ecuación en diferencias: $$X_t + \\phi_1 X_{t-1} +\n\\cdots + \\phi_q X_{t-q} = U_t.$$\n\n"]},{"cell_type":"markdown","id":"d049c030-269e-4175-801d-09fc2535d80c","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["El problema con la anterior definición es que la ecuación\n$\\boldsymbol{\\phi}*\\boldsymbol{X}=\\boldsymbol{U}$ no tiene solución\núnica (y en algunos casos ninguna solución es\nestacionaria). Despejemos $\\boldsymbol{X}$ para verlo.\n\nMultiplicando ambos lados de la ecuación por una inversa de\n$\\boldsymbol{\\phi}$ lo logramos:\n$$\\boldsymbol{X}=inversa(\\boldsymbol{\\phi})*\\boldsymbol{U}.$$ Y si\ndenotamos la secuencia $inversa(\\boldsymbol{\\phi})$ con\n$\\boldsymbol{a}$ entonces\n$$X_t=\\boldsymbol{a}(\\mathsf{B})U_t=\\sum_{j\\in\\mathbb{Z}} a_j\nU_{t-j}.$$\n\n"]},{"cell_type":"markdown","id":"2a2190e3-9299-4039-9d48-93ea7c2cbb9d","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Pero&#x2026; ¿Qué secuencia $\\boldsymbol{a}$ usamos como inversa de\n$\\boldsymbol{\\phi}$? Recuerde que hay infinitas y la mayoría no son\nsumables (si el polinomio $\\boldsymbol{\\phi}$ tiene raíces unitarias\nninguna lo es).\n\n<div class=\"org-center\">\n<p>\nEn tal caso la expresión\n$\\;\\boldsymbol{a}(\\mathsf{B})U_t=\\sum\\limits_{j=-\\infty}^\\infty a_j\nU_{t-j}\\;$ carece de sentido (pues no converge).\n</p>\n</div>\n\n"]},{"cell_type":"markdown","id":"1116903d-e5ed-4ccf-ac90-21bed53f694a","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["**Requisitos** sobre el polinomio autorregresivo $\\boldsymbol{\\phi}$\n\n1.  Para tener un <u>proceso lineal</u>, exigiremos que $\\boldsymbol{\\phi}$\n    <u>no tenga raíces de módulo 1</u>.\n    \n    Entonces existe una única inversa absolutamente sumable: $\\boldsymbol{\\phi}^{-1} \\in\n       \\ell^1\\subset\\ell^2$.\n    \n    La inversa $\\boldsymbol{a}=\\boldsymbol{\\phi}^{-1}$ corresponde a la\n    única solución *estacionaria* de\n    $\\boldsymbol{\\phi}*\\boldsymbol{X}=\\boldsymbol{U}$.  (Si\n    $\\boldsymbol{\\phi}$ tuviera raíces de módulo 1 no existiría ni\n    $\\boldsymbol{\\phi}^{-1}$, ni la solución estacionaria).\n    \n    $$X_t=\\boldsymbol{\\phi}^{-1}(\\mathsf{B})U_t=\\sum_{j=-\\infty}^\\infty a_j U_{t-j}$$\n\n2.  Para tener un <u>proceso lineal causal</u> exigiremos que las raíces de\n    $\\boldsymbol{\\phi}$ sean mayores que 1 en valor absoluto (<u>raíces\n    fuera del círculo unidad</u>):\n    $\\boldsymbol{\\phi}^{-1}=\\boldsymbol{\\phi}^{-\\triangleright}$.\n    \n    $$X_t=\\boldsymbol{\\phi}^{-1}(\\mathsf{B})U_t=\\sum_{j=0}^\\infty a_j U_{t-j}$$\n\n"]},{"cell_type":"markdown","id":"3c9745ce-1662-4267-a319-cc369f462f3b","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["El siguiente modelo lineal es una combinación (o generalización) de\nlos dos anteriores.\n\n"]},{"cell_type":"markdown","id":"6fc407dd-f5cf-49c6-b345-913bac1accd6","metadata":{"slideshow":{"slide_type":"slide"}},"source":["#### Proceso autorregresivo de media móvil. ARMA($p,q$)\n\n"]},{"cell_type":"markdown","id":"c11f2c87-9f3f-4ab8-9d92-cf9b726bcd28","metadata":{},"source":["Sea $\\;\\boldsymbol{U}\\sim WN(0,\\sigma^2)\\;$, se denomina *proceso\nautorregresivo de media móvil $(p,q)$* al proceso estocástico\nestacionario $\\;\\boldsymbol{X}\\;$ que es la solución de la ecuación en\ndiferencias:\n$$\\boldsymbol{\\phi}*\\boldsymbol{X}=\\boldsymbol{\\theta}*\\boldsymbol{U}$$\ndonde el polinomio *autorregresivo* $\\;\\boldsymbol{\\phi}\\;$ tiene\n<u>grado $p$</u> con ${\\color{#008000}{\\phi_{0}=1}}$ y con todas sus raíces\nfuera del círculo unidad (*por los motivos anteriormente vistos*); y\nel polinomio *de media móvil* $\\;\\boldsymbol{\\theta}\\;$ es <u>de grado\n$q$</u> con ${\\color{#008000}{\\theta_{0}=1}}$;\n\n$$\\text{es decir,}\\qquad\n\\boldsymbol{X}=\\frac{\\boldsymbol{\\theta}}{\\boldsymbol{\\phi}}*\\boldsymbol{U};\n\\qquad\\text{donde}\\;\n\\frac{\\boldsymbol{\\theta}}{\\boldsymbol{\\phi}}\\equiv\\boldsymbol{\\phi}^{-1}*\\boldsymbol{\\theta}$$\n\n"]},{"cell_type":"markdown","id":"e9a2f551-40b4-4ab1-b171-34f69c30523a","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Tanto $\\boldsymbol{\\phi}^{-1}$ como $\\boldsymbol{\\theta}$ son\nabsolutamente sumables y como $\\ell^1$ es un anillo,\n$\\boldsymbol{\\phi}^{-1}*\\boldsymbol{\\theta}\\equiv\\frac{\\boldsymbol{\\theta}}{\\boldsymbol{\\phi}}\\in\\ell^1$\n(también es absolutamente sumable y por tanto de cuadrado sumable),\nconsecuentemente el proceso estocástico es un proceso lineal.\n$$X_t=\\frac{\\boldsymbol{\\theta}}{\\boldsymbol{\\phi}}(\\mathsf{B})U_t=\\sum_{j=0}^\\infty\na_j U_{t-j}$$ donde\n$\\boldsymbol{a}=\\boldsymbol{\\phi}^{-1}*\\boldsymbol{\\theta}$.\n\n"]},{"cell_type":"markdown","id":"b4f49732-30c5-4438-882b-7ba019532803","metadata":{"slideshow":{"slide_type":"notes"}},"source":["#### Proceso autorregresivo de media móvil con media no nula\n\n"]},{"cell_type":"markdown","id":"deac7d11-1496-4a69-9d02-8fb77f94a31b","metadata":{"slideshow":{"slide_type":"notes"}},"source":["Por último, consideremos un proceso $\\boldsymbol{Y}$ con media\ndistinta de cero, es decir, $$E(Y_t)=\\mu\\ne0$$ y definamos la\nsecuencia constante $\\boldsymbol{\\mu}=\\sum\\limits_{j\\in\\mathbb{Z}} \\mu\nz^j=(\\ldots,\\mu,\\mu,\\mu,\\ldots)$. \n\\medskip\n\nDecimos que $\\boldsymbol{Y}$ es un proceso ARMA($p,q$) con media\ndistinta de cero si $\\boldsymbol{X}$ es ARMA($p,q$)\n$$\\boldsymbol{\\phi}*\\boldsymbol{X}=\\boldsymbol{\\theta}*\\boldsymbol{U}$$\ndonde $\\boldsymbol{X}=\\boldsymbol{Y}-\\boldsymbol{\\mu}$ es\nevidentemente un proceso de media cero.  Por tanto\n\n\\begin{align*}\n\\boldsymbol{\\phi}*(\\boldsymbol{Y}-\\boldsymbol{\\mu})=&\\boldsymbol{\\theta}*\\boldsymbol{U}\\\\\n\\boldsymbol{\\phi}*\\boldsymbol{Y}-\\boldsymbol{\\phi}*\\boldsymbol{\\mu}=&\\boldsymbol{\\theta}*\\boldsymbol{U}\\\\\n\\boldsymbol{\\phi}*\\boldsymbol{Y}=&\\boldsymbol{\\phi}*\\boldsymbol{\\mu}+ \\boldsymbol{\\theta}*\\boldsymbol{U}\\\\\n\\end{align*}\n\nEs decir, si $\\boldsymbol{\\phi}(\\mathsf{B})$ es\n$\\;1-\\phi_1\\mathsf{B}-\\phi_2\\mathsf{B}^2-\\cdots-\\phi_p\\mathsf{B}^p,\\;$\nentonces $$\\boldsymbol{\\phi}(B){Y_t}=c+\\boldsymbol{\\theta}(B){U_t}$$\ndonde $$\\;c=(1-\\phi_1-\\phi_2-\\cdots-\\phi_p)\\mu\\;$$ y donde\n$\\;\\mu=E(Y_t)$, es un proceso autorregresivo de media móvil\nARMA($p,q$) *con media no nula*.\n\n"]}],"metadata":{"org":null,"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.3.2"}},"nbformat":4,"nbformat_minor":5}