{"cells":[{"cell_type":"markdown","id":"08c683ce-82a6-4694-b1ab-8acbb4617bd5","metadata":{},"source":"Econometría Aplicada. Lección 2\n===============================\n\n**Author:** Marcos Bujosa\n\n"},{"cell_type":"markdown","id":"f2c1b7df-075a-42ba-909d-09d1692c0b9a","metadata":{},"source":["<div class=\"ABSTRACT\" id=\"org3488459\">\n<p>\nEn esta lección veremos algunos modelos de regresión con series\ntemporales; en particular la estimación de componentes (no\nobservables) con modelos deterministas. También los efectos de la\nautocorrelación en las perturbaciones y como lidiar con ellos.\n</p>\n\n</div>\n\n-   [lección en html](https://mbujosab.github.io/EconometriaAplicada-SRC/Lecc02.html)\n-   [lección en mybinder](https://mybinder.org/v2/gh/mbujosab/EconometriaAplicada-SRC/HEAD?labpath=Lecc02.ipynb)\n\n"]},{"cell_type":"markdown","id":"a7e3a2d9-4edc-41ac-be76-3d517f7480e8","metadata":{"slideshow":{"slide_type":"skip"}},"source":["#### Carga de algunos módulos de python\n\n"]},{"cell_type":"code","execution_count":1,"id":"b5236181-7e02-4aed-a716-ac0741c6b7e6","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# Importamos algunos módulos de python\nimport numpy as np # linear algebra\nimport pandas as pd # dataframe processing\nimport statsmodels.api as sm  # modelos estadísticos\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt # data visualization\n# definimos parámetros para mejorar los gráficos\nmpl.rc('text', usetex=True)\nmpl.rc('text.latex', preamble=r'\\usepackage{amsmath}')\nfrom matplotlib import rcParams\nrcParams['figure.figsize'] = 15,5"]},{"cell_type":"code","execution_count":1,"id":"a29fc366-6212-4dfe-9326-9678202e50e8","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# Usaré la siguiente función para transformar salidas en \\LaTeX{} de statsmodels a ficheros png \n# que incluiré en las transparencias\nfrom sympy.printing.preview import preview\ndef repr_png(tex, ImgFile):\n    preamble = \"\\\\documentclass[10pt,preview]{standalone}\\n\" \\\n        \"\\\\usepackage{booktabs,amsmath,amsfonts}\\\\begin{document}\"    \n    preview(tex, filename=ImgFile, viewer='file', preamble=preamble, dvioptions=['-D','250'])"]},{"cell_type":"markdown","id":"0913e504-bf4e-495a-82ec-8be85df56a6d","metadata":{"slideshow":{"slide_type":"skip"}},"source":["##### Lectura datos: Internat. airline passengers. Monthly totals in thousands. Jan 49 – Dec 60\n\n"]},{"cell_type":"code","execution_count":1,"id":"482d5910-c835-426a-90d3-b57e4b87eec2","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# Leemos los datos de un fichero csv y generamos un dataframe de pandas cuyo índice es el tiempo\nOrigData = pd.read_csv('./database/Datasets-master/airline-passengers.csv')\nOrigData['Month'] = pd.to_datetime(OrigData['Month'])\nOrigData = OrigData.set_index(['Month'])\nprint(OrigData.head())"]},{"cell_type":"code","execution_count":1,"id":"7c499ef8-596a-499e-902f-6dd373d50afd","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# Creamos un dataframe con el mismo índice temporal de los datos originales pero con los datos en logaritmos\nTransformedData = pd.DataFrame(index=OrigData.index)\nTransformedData['dataLog'] = np.log(OrigData['Passengers'])\nprint(TransformedData.head())"]},{"cell_type":"markdown","id":"5e5dd4c7-0ac2-4372-b3b5-ce7f3c758058","metadata":{"slideshow":{"slide_type":"slide"}},"source":["## Descomposición estructural de una serie temporal\n\n"]},{"cell_type":"markdown","id":"0d061903-46af-4600-8d07-29bba92d72f4","metadata":{},"source":["En la lección anterior vimos que una estrategia para analizar series\ntemporales es transformar los datos para\n\n1.  primero lograr que sean \"***estacionarios***\"\n2.  después, mediante más transformaciones, lograr una secuencia de\n    \"***ruido blanco***\" (este segundo paso lo veremos cuando veamos los modelos ARIMA)\n\n(recuerde que las expresiones *datos estacionarios* y *secuencia de\nruido blanco* son un abuso del lenguaje).\n\n"]},{"cell_type":"markdown","id":"f29f7cce-d0cb-49ab-a6ef-2f6526a799ee","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["Pero existe otro enfoque que pretende descomponer la serie temporal en\nlos siguientes componentes *no observables* (o en un subconjunto de\nellos):\n\n$$\\boldsymbol{y} = \\boldsymbol{t} + \\boldsymbol{c} + \\boldsymbol{s} + \\boldsymbol{e}$$\n\ndonde:\n\n-   **La tendencia \"$\\boldsymbol{t}$\":** recoge la lenta evolución de la\n    media a *largo plazo*.\n\n-   **El componente estacional \"$\\boldsymbol{s}$\":** recoge oscilaciones\n    periódicas que se repiten regularmente en ciclos estacionales (o\n    semanales, u horarios, etc.).\n\n-   **El componente cíclico \"$\\boldsymbol{c}$\":** Cuando aparece\n    explícitamente en el modelo, $\\boldsymbol{c}$ recoge las\n    oscilaciones a medio plazo. Es decir, aquellas de un plazo más largo\n    que las oscilaciones estacionales, pero más corto que la tendencia\n    de largo plazo. Si está ausente, dichas oscilaciones suelen aparecer\n    en el componente de la tendencia, que entonces también podemos\n    denominar *tendencia-ciclo*.\n\n-   **El componente irregular \"$\\boldsymbol{e}$\":** recoge las\n    oscilaciones no captadas por el resto de componentes, pues:\n    $\\boldsymbol{e} = \\boldsymbol{y} - \\boldsymbol{t} - \\boldsymbol{c} -\n      \\boldsymbol{s}$.\n\nAjuste aceptable si (como poco) el componente irregular\n$\\boldsymbol{e}$ parece \"*estacionario*\".\n\n"]},{"cell_type":"markdown","id":"e6bbaa56-0f40-4da2-8f52-ad65bd96d3a3","metadata":{"slideshow":{"slide_type":"slide"}},"source":["### Tendencia determinista *lineal*\n\n"]},{"cell_type":"code","execution_count":1,"id":"5d64543a-7ae5-4518-a98e-3cc34d6dbce3","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# Ajustamos por MCO una tendencia linea. \n# Para ello, primero creamos un DataFrame con el regresando y los regresores del modelo\ndatosModelo1 = TransformedData[['dataLog']].copy()\nnsample = len(datosModelo1)\ndatosModelo1['cte'] = [1]*nsample\ndatosModelo1['time'] = np.linspace(1, nsample, nsample)\nmodel1 = sm.OLS(datosModelo1['dataLog'], datosModelo1[['cte', 'time']])\nresults1 = model1.fit()"]},{"cell_type":"code","execution_count":1,"id":"2888b068-3d59-474f-83c9-e597e80c0689","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["#Añadimos al DataFrame =datosModelo1= la tendencia ajustada, los residuos y la diferencia estacional de los residuos.\ndatosModelo1['yhat'] = datosModelo1['cte']*results1.params['cte']+datosModelo1['time']*results1.params['time']\ndatosModelo1['ehat'] = results1.resid\ndatosModelo1['ehatDiff12'] = datosModelo1['ehat'].diff(12)"]},{"cell_type":"code","execution_count":1,"id":"32d4a1f9-be4e-4851-b459-421e147ba6a7","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# Dibujamos los datos junto a la tendencia estimada\nplt.plot(datosModelo1['dataLog'])\nplt.plot(results1.fittedvalues)\nplt.grid()  \nplt.ylabel(r\"Log-Passengers, ($\\ln\\boldsymbol{x}$) \")"]},{"cell_type":"markdown","id":"cbb1b4ff-82b2-4f88-a603-0e1ad4c8afd1","metadata":{},"source":["El modelo de tendencia más simple es la recta de regresión (donde el\nregresor no constante es el índice $t$):\n\n$$\\ln{y_t}=\\underbrace{\\beta_1+\\beta_2\\cdot t}_{\\text{tendencia}} + e_t; \\quad t=1:114$$\n\n"]},{"cell_type":"markdown","id":"71f512d1-3e69-4b5a-8ac4-2d32a10d3276","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["![img](./img/lecc02/airlinepass+linearTrend.png)\n\n$$\\widehat{\\ln{y_t}}=4.8137+0.01\\cdot\\big(t\\big), \\qquad t=1:114$$\n\n"]},{"cell_type":"code","execution_count":1,"id":"ebdb264f-1cb0-4367-9908-937bf0b084a9","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["print(results1.summary())"]},{"cell_type":"markdown","id":"c288ea66-e423-4b4f-8be8-306a308ea9a3","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["![img](./img/lecc02/resultsModel1.png)\n\n"]},{"cell_type":"markdown","id":"7b0b837f-1745-45dd-8a68-b129d14fcf32","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["**<u>Componente irregular</u>**\n\n"]},{"cell_type":"code","execution_count":1,"id":"0819efe4-aa02-43d8-b7a6-2f346256a4a0","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# Gráfico de los residuos del ajuste.\nplt.grid()  \nplt.plot(results1.resid)"]},{"cell_type":"markdown","id":"d1ad0f26-dacc-44b6-b1e7-99f9badf496b","metadata":{},"source":["![img](./img/lecc02/airlinepass+irreg.png)\n\nEn este caso, el ajuste del modelo \n\n$$\\boldsymbol{y} = \\boldsymbol{t} + \\boldsymbol{e},$$\n\n(donde $\\boldsymbol{t}$ es una tendencia lineal)\nno es satisfactorio, ya que el *componente irregular*\n$$\\boldsymbol{e}=\\boldsymbol{y}-\\boldsymbol{t}$$ no tiene la\napariencia de realización de un proceso estacionario.\n\n"]},{"cell_type":"code","execution_count":1,"id":"df653288-92fd-4029-bc86-96469d6cf8d1","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# Gráfico de la diferencia estacional de los residuos del ajuste.\nplt.grid()  \nplt.plot(datosModelo1['ehatDiff12'])"]},{"cell_type":"markdown","id":"fd07ea88-88ad-47c3-965e-7416d8d98358","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["Adicionalmente podemos ver que la diferencia de orden 12 del\ncomponente irregular parece mostrar un componente cíclico con un\nperiodo de unos 4 años.\n\n![img](./img/lecc02/airlinepass+irregDiff12.png)\n\nEn el siguiente ejercicio probaremos con una tendencia cuadrática&#x2026;\n\n"]},{"cell_type":"markdown","id":"e6693a4d-6dbb-4473-84f7-7f0340a644e6","metadata":{"slideshow":{"slide_type":"slide"}},"source":["### Tendencia determinista *cuadrática*\n\n"]},{"cell_type":"code","execution_count":1,"id":"4626e2cb-369b-4a3c-9a7a-520eae520ad8","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[{"name":"stdout","output_type":"stream","text":"ajuste-tendencia-cuadratica"}],"source":["# creamos un DataFrame con el regresando y los regresores del modelo :results silent.\ndatosModelo2 = TransformedData[['dataLog']].copy()\nnsample = len(datosModelo1)\ndatosModelo2['cte'] = [1]*nsample\ndatosModelo2['time'] = np.linspace(1, nsample, nsample)\ndatosModelo2['sq_time'] = [t**2 for t in datosModelo2['time']]\n# Ajustamos por MCO una tendencia cuadrática a los datos.\nmodel2 = sm.OLS(datosModelo1['dataLog'], datosModelo2[['cte', 'time', 'sq_time']])\nresults2 = model2.fit()"]},{"cell_type":"code","execution_count":1,"id":"55325313-a58c-4ca6-8d45-2921f802fe77","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# Añadimos al DataFrame 'datosModelo2' la tendencia ajustada, los residuos y la diferencia estacional de los residuos.\ndatosModelo2['yhat'] = results2.fittedvalues\ndatosModelo2['ehat'] = results2.resid\ndatosModelo2['ehatDiff12'] = datosModelo2['ehat'].diff(12)"]},{"cell_type":"code","execution_count":1,"id":"abc9c9b2-2d4a-49eb-9c46-3852eb449f84","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# Dibujamos los datos junto a la tendencia estimada.\nplt.plot(datosModelo1['dataLog'])\nplt.plot(results2.fittedvalues)\nplt.grid()  \nplt.ylabel(r\"Log-Passengers, ($\\ln\\boldsymbol{x}$) \")"]},{"cell_type":"markdown","id":"15fba132-e935-4873-b89d-0ce10c5323c0","metadata":{},"source":["$$\\ln{y_t}=\\underbrace{\\beta_1+\\beta_2\\cdot t + \\beta_3\\cdot t^2}_{\\text{tendencia}} + e_t; \\quad t=1:114$$\n\n"]},{"cell_type":"markdown","id":"5a9a8a55-31a3-4d66-b1da-a360a67da7bf","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["![img](./img/lecc02/airlinepass+quadraticTrend.png)\n\n$$\\widehat{\\ln{y_t}}=4.7364+(0.0132)\\cdot t +(-2.191e-05)\\cdot t^2, \\qquad t=1:114$$\n\n"]},{"cell_type":"code","execution_count":1,"id":"510a23cd-dcbc-46c5-8966-720ee1256559","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["print(results2.summary())"]},{"cell_type":"markdown","id":"6ea2e769-fdac-4fae-956e-8639eba0dea3","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["![img](./img/lecc02/resultsModel2.png)\n\n"]},{"cell_type":"markdown","id":"d473d1e3-1903-447c-834a-77c82a82fe75","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["**<u>Componente irregular</u>**\n\n"]},{"cell_type":"code","execution_count":1,"id":"627a5de0-cc81-4034-934b-85b38168b360","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["plt.grid()  \nplt.plot(results2.resid)"]},{"cell_type":"markdown","id":"95d0d2f9-0697-44fc-8478-1e30da18fd1e","metadata":{},"source":["![img](./img/lecc02/airlinepass+irreg2.png)\n\nDe manera análoga al caso anterior, el ajuste del modelo\n\n$$\\boldsymbol{y} = \\boldsymbol{t} + \\boldsymbol{e}$$\n\n(donde $\\boldsymbol{t}$ ahora es una *tendencia\ncuadrática*) tampoco es satisfactorio, puesto que el componente\nirregular $\\boldsymbol{e}$ sigue sin parecerse a la realización de un\nproceso estacionario.\n\n"]},{"cell_type":"code","execution_count":1,"id":"e0537a8c-7cc8-4a82-ac2f-2a439f1d3b94","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["plt.grid()  \nplt.plot(datosModelo2['ehatDiff12'])"]},{"cell_type":"markdown","id":"1926c944-ded0-4ec8-a598-973b4f4da338","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["También en este modelo la diferencia de orden 12 del componente\nirregular muestra un componente cíclico con un periodo de unos 4 años.\n\n![img](./img/lecc02/airlinepass+irregDiff12.png)\n\nPara obtener una *tendencia-ciclo* que capte este ciclo son necesarios\nprocedimientos más sofisticados (por ejemplo TRAMO-SEATS, o X13-ARIMA,\no STAMP, o LDHR, o E4, etc.) que estiman tendencias y componentes\nestacionales estocásticos.\n\n"]},{"cell_type":"markdown","id":"1e694796-e0c2-4831-ba94-db158c79e48f","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["En el siguiente ejercicio estimaremos un **componente estacional\ndeterminista** (junto a una tendencia cuadrática determinista).\n\n"]},{"cell_type":"markdown","id":"453c7dd1-9cee-414c-bf46-cfd533bb995c","metadata":{"slideshow":{"slide_type":"slide"}},"source":["### Tendencia cuadrática más estacionalidad determinista mediante *dummies*\n\n"]},{"cell_type":"code","execution_count":1,"id":"cf72f5a6-de5f-4f87-b1cb-5fd8e4cf1b96","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# Creamos un dataframe con los datos y los regresores 'cte', 't' y ' :results silentt^2'\ndf = TransformedData[['dataLog']].copy()\nnsample = len(df)\ndf['cte']     = [1]*nsample\ndf['time']    = np.linspace(1, nsample, nsample)\ndf['sq_time'] = [t**2 for t in df['time']]"]},{"cell_type":"code","execution_count":1,"id":"99ff108d-d970-4fb1-b6f7-2f1b7a635f89","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# Creamos las /dummies/ estacionales\nfrom statsmodels.tsa.deterministic import Seasonality\nseas_gen = Seasonality(12, initial_period=1)\nseasonalDummies = seas_gen.in_sample(df.index)"]},{"cell_type":"code","execution_count":1,"id":"63d957f6-4003-4f41-8313-9061643a9f6c","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# Creamos un dataframe con el regresando y todos los regresores del modelo\ndatosModelo3 = pd.concat([df, seasonalDummies],axis=1)\n# realizamos la regresión de la primera columna ('dataLog') sobre el resto de columnas del dataframe.\nmodel3 = sm.OLS(datosModelo3['dataLog'], datosModelo3.iloc[:,1:-1])\nresults3 = model3.fit()"]},{"cell_type":"code","execution_count":1,"id":"af7858a8-fa7d-4171-9f21-d3b20d80621b","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# La combinación lineal de los regresores 'cte', 'time' y 'sq_time' usando los correspondientes\n# parámetros estimados nos da el componente de tendencia (determinista) estimado. \nTrendComp = datosModelo3[['cte','time','sq_time']].dot(results3.params[['cte','time','sq_time']])"]},{"cell_type":"code","execution_count":1,"id":"bc89cf3e-d9ec-44f6-93c9-277db76bdaa2","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["rcParams['figure.figsize'] = 15,4\nplt.plot(datosModelo1['dataLog'])\nplt.plot(TrendComp)\nplt.grid()  \nplt.ylabel(r\"Log-Passengers, ($\\ln\\boldsymbol{x}$) \")"]},{"cell_type":"markdown","id":"c4ce4851-6ca3-4176-8257-85f5d9aad91c","metadata":{},"source":["![img](./img/lecc02/airlinepass+TrendC.png)\n\n"]},{"cell_type":"code","execution_count":1,"id":"c453768b-a59c-44c0-8728-bd697dc0a72d","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["SeasonalComp = (seasonalDummies.iloc[:,:-1]).dot(results3.params[3:])\nplt.grid()  \nplt.plot(SeasonalComp)"]},{"cell_type":"markdown","id":"11bad6c4-527b-427b-9f77-f6d809c298c2","metadata":{},"source":["![img](./img/lecc02/airlinepass+SeasonalC.png)\n\n"]},{"cell_type":"markdown","id":"e24b68db-cccc-4398-8e00-75f074593135","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["#### Ajuste y componente irregular $\\boldsymbol{e}=\\boldsymbol{y}-\\boldsymbol{t}-\\boldsymbol{s}$\n\n"]},{"cell_type":"code","execution_count":1,"id":"aa4f35af-4964-435f-9193-615e895c0d3a","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["plt.grid()  \nplt.plot(datosModelo3['dataLog'])\nplt.plot(TrendComp + SeasonalComp)"]},{"cell_type":"markdown","id":"ce5620de-4254-431f-aac6-c45de868794d","metadata":{},"source":["![img](./img/lecc02/airlinepass+yhat.png)\n\n"]},{"cell_type":"code","execution_count":1,"id":"e71863f0-dc33-4f2a-b00f-43eca2350470","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["plt.grid()  \nplt.plot(results3.resid)"]},{"cell_type":"markdown","id":"7003e954-7b39-42f2-858b-46abaa5dcc07","metadata":{},"source":["![img](./img/lecc02/airlinepass+IrregC.png)\n\n"]},{"cell_type":"markdown","id":"de8811dc-a7a2-4866-ad4f-a82ce21bc8c2","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["#### Valoración de modelos con componentes deterministas\n\n"]},{"cell_type":"markdown","id":"1becfc4a-40af-4fb9-b338-b1584abd44a3","metadata":{},"source":["-   Estos modelos resultan útiles para realizar un análisis descriptivo.\n\n-   Pero suelen funcionar bastante mal como herramienta de predicción:\n    -   no tienen en cuenta la dependencia inter-temporal de los datos (se\n        estiman mediante regresión, es decir, como si los datos fueran de\n        sección cruzada)\n    \n    -   Por ejemplo, a la hora de prever el dato de enero de 1961, en este\n        modelo pesa tanto el dato de enero de 1949 como el dato de enero\n        de 1960.\n\nEn general, para que los modelos funcionen bien en predicción deben\n*dar un mayor peso a los datos recientes* frente a los datos alejados\nen el tiempo.\n\nPero sigamos explorando este modelo&#x2026;\n\n"]},{"cell_type":"markdown","id":"c31f0ee0-ea10-4578-aadf-694936c11e81","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["**Hay parámetros no significativos&#x2026;** (p-valores para dummies enero,\nfebrero y octubre).\n\n"]},{"cell_type":"code","execution_count":1,"id":"35efa9d7-b0f0-4a25-836b-6bf9a5b0fc3a","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["repr_png(results3.summary().as_latex(), \"./img/lecc02/resultsModel3.png\")"]},{"cell_type":"markdown","id":"84bf8438-92d8-4ebb-a797-50eeceb7248b","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["<div>\n<img src=\"./img/lecc02/resultsModel3.png\" width=\"400\" class=\"center\"/>\n</div>\n\n"]},{"cell_type":"markdown","id":"20ce0e25-533f-40e6-96e7-ee55a4810b39","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["**podemos eliminarlos secuencialmente** (quitando cada vez la variable de mayor p-valor)\n\n"]},{"cell_type":"code","execution_count":1,"id":"9ef9646c-c176-4376-9a16-05d2f9934ae2","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["import operator\ndef remove_most_insignificant(df, results):\n    # use operator to find the key which belongs to the maximum value in the dictionary:\n    max_p_value = max(results.pvalues.items(), key=operator.itemgetter(1))[0]\n    # this is the feature you want to drop:\n    df.drop(columns = max_p_value, inplace = True)\n    return df"]},{"cell_type":"code","execution_count":1,"id":"dc4419fe-4717-4bf2-a373-5ba3a46373a1","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["y = datosModelo3['dataLog']\nX = datosModelo3.iloc[:,1:-1]\nsignificacion = 0.05\ninsignificant_feature = True\nwhile insignificant_feature:\n        model4 = sm.OLS(y, X)\n        results4 = model4.fit()\n        significant = [p_value < significacion for p_value in results4.pvalues]\n        if all(significant):\n            insignificant_feature = False\n        else:\n            if X.shape[1] == 1:  # if there's only one insignificant variable left\n                print('No significant features found')\n                results4 = None\n                insignificant_feature = False\n            else:            \n                X = remove_most_insignificant(X, results4)\n\nprint(results4.summary())"]},{"cell_type":"markdown","id":"24ed7268-2a6b-45ac-8807-c15bcb0cf95b","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["<div>\n<img src=\"./img/lecc02/resultsModel4.png\" width=\"400\" class=\"center\"/>\n</div>\n\n\n\nPero esta inferencia es incorrecta. En presencia de auto-correlación\n**la estimación por defecto de las desviaciones típicas del estimador\nMCO es incorrecta**. Veámoslo:\n\n"]},{"cell_type":"markdown","id":"ce406d46-3272-44be-9100-c9e2c2d340ae","metadata":{"slideshow":{"slide_type":"slide"}},"source":["## Perturbaciones no esféricas\n\n"]},{"cell_type":"markdown","id":"7c849848-6b2e-4d5f-a869-bbdb7a369c7b","metadata":{},"source":["Considere el modelo\n$\\boldsymbol{y}=\\boldsymbol{\\mathsf{X}\\beta}+\\boldsymbol{U}.\\;$ Bajo\nlos supuestos habituales\n\n$$E(\\boldsymbol{U}\\mid\\boldsymbol{\\mathsf{X}})=\\boldsymbol{0},\\quad\nVar(\\boldsymbol{U}\\mid\\boldsymbol{\\mathsf{X}})=\\sigma^2\\boldsymbol{\\mathsf{I}}\\quad\n\\text{y} \\quad E(\\boldsymbol{\\mathsf{X'X}}) \\text{ es invertible}$$\n\nel estimador\n$\\;\\widehat{\\boldsymbol{\\beta}}=(\\boldsymbol{\\mathsf{X'X}})^{-1}\\boldsymbol{\\mathsf{X'}Y}\\;$\nes insesgado y eficiente, con varianza\n\n$$\\;Var(\\widehat{\\boldsymbol{\\beta}}\\mid\\boldsymbol{\\mathsf{X}})=\\sigma^2(\\boldsymbol{\\mathsf{X'X}})^{-1}$$\n\n"]},{"cell_type":"markdown","id":"7633f859-1d64-42bd-88b1-b35c538e3c1d","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["Pero si las perturbaciones $\\boldsymbol{U}$ del modelo son\nheterocedásticas y/o autocorreladas\n$$Var(\\boldsymbol{U}\\mid\\boldsymbol{\\mathsf{X}})=\\boldsymbol{\\Sigma}\\ne\\sigma^2\\boldsymbol{\\mathsf{I}}$$\nentonces el estimador $\\widehat{\\boldsymbol{\\beta}}$, aunque\ninsesgado, ya no es eficiente; y su varianza es\n\n$$Var(\\widehat{\\boldsymbol{\\beta}}\\mid\\boldsymbol{\\mathsf{X}})=Var(\\widehat{\\boldsymbol{\\beta}}-\\boldsymbol{\\mathsf{I}}\\boldsymbol{\\beta}\\mid\\boldsymbol{\\mathsf{X}})=\n(\\boldsymbol{\\mathsf{X'X}})^{-1}\\boldsymbol{\\mathsf{X'}}\n\\boldsymbol{\\Sigma}\n\\boldsymbol{\\mathsf{X}}(\\boldsymbol{\\mathsf{X'X}})^{-1}.$$\n\n"]},{"cell_type":"markdown","id":"1dfd93f2-3e00-46ab-b91f-520b1d7ed7ae","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["### Test de autocorrelación de Breusch y Godfrey\n\n"]},{"cell_type":"markdown","id":"96375eb8-f37a-41a5-94f9-b970eb669d95","metadata":{},"source":["El tests Breusch-Godfrey (y el Durbin-Watson) contrasta la $H_0$ de\n*no autocorrelación*.\n\n"]},{"cell_type":"markdown","id":"fb5f5d50-7f41-42da-9eef-c7c50f1211c0","metadata":{"slideshow":{"slide_type":"fragment"}},"source":["\nConsidere el *modelo de regresión lineal* \n\n\\begin{equation}\n\\label{orgf3c4d85}\nY_t = \\beta_1+ \\beta_2 X_{t,1} + \\cdots +  \\beta_k X_{t,k+1} + U_t \n\\end{equation}\n\n\ndonde las perturbaciones $\\boldsymbol{U}$ quizá siguen un esquema\nauto-regresivo $AR(p)$:\n\n$$U_t = \\rho_1 U_{t-1} + \\rho_2 U_{t-2}  + \\cdots + \\rho_p U_{t-p} + \\varepsilon_t$$\n\n-   **Paso 1**. Obtener los errores $\\hat{\\boldsymbol{e}}$ de ajuste MCO\n    de ([1](#orgf3c4d85)) (muestra de tamaño $T$)\n-   **Paso 2**. Calcular el $R^2$ de la *regresión auxiliar* de los\n    errores $\\hat{\\boldsymbol{e}}$ sobre los regresores del modelo\n    original ([1](#orgf3c4d85)) y sobre los $p$ primeros retardos\n    de $\\hat{\\boldsymbol{e}}$.  $$\\hat{e}_t = \\alpha_0 + \\alpha_1\n      X_{t,1} + \\cdots \\alpha_k X_{t,k} + \\rho_1 \\hat{e}_{t-1} + \\rho_2\n      \\hat{e}_{t-2} + \\cdots + \\rho_p \\hat{e}_{t-p} + \\varepsilon_t$$\n\nAsintóticamente y bajo la $H_0$ de *no autocorrelación*: $\\quad\\rho_i = 0\\text{ para todo }i$\n\n$$n R^2\\,\\sim\\,\\chi^2_p,$$\n\n\ndonde $R^2$ es el coeficiente de determinación de la regresión\nauxiliar y $n=T-p$.\n\n"]},{"cell_type":"code","execution_count":1,"id":"3957cf99-b0cb-4662-88dc-37fca6d15493","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["import statsmodels.stats.diagnostic as dg\n#perform Breusch-Godfrey t :results silentest of order p = 3\narbg = dg.acorr_breusch_godfrey(results4, nlags=3, store=True)\narbg[:1]\nrepr_png(arbg[-1].resols.summary().as_latex(), \"./img/lecc02/resultsBreusch-Godfrey.png\")"]},{"cell_type":"markdown","id":"eb0bbff0-8a6d-4001-b511-a4076977bb03","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["-   Valor del estadístico: $\\quad 62.7119\\qquad$ (p-valor: $\\; 1.55e-13$)\n-   $x_{12}$ corresponde al primer retardo en la regresión auxiliar y es muy significativo\n\n<div>\n<img src=\"./img/lecc02/resultsBreusch-Godfrey.png\" width=\"450\" class=\"center\"/>\n</div>\n\n"]},{"cell_type":"markdown","id":"44da5c6d-7475-4e7d-9100-7be04da287b7","metadata":{"slideshow":{"slide_type":"notes"}},"source":["### Test de Durbin-Watson\n\n"]},{"cell_type":"markdown","id":"f1ba59f7-02a5-4455-b8b7-6d74f2a8a299","metadata":{},"source":["El test de Durbin-Watson contrasta la autocorrelación <u>de orden\nuno</u>. Para muestras grandes, el test es aproximadamente igual a\n$2(1-{\\hat {\\rho }})$, donde ${\\hat{\\rho}}$ es la autocorrelación de\norden uno de los residuos. Por tanto, valores del test próximos a 2\nindican no autocorrelación, valores próximos a 0 indican fuerte\nautocorrelación positiva y valores próximos a 4 indican fuerte\nautocorrelación negativa.\n\n"]},{"cell_type":"markdown","id":"42ac18b4-1451-4e80-a87c-b5880b5e37d3","metadata":{"slideshow":{"slide_type":"slide"}},"source":["### Errores estándar robustos\n\n"]},{"cell_type":"markdown","id":"620da22f-1e5f-416d-9179-af118352985f","metadata":{},"source":["Un procedimiento adecuado en presencia de autocorrelación y muestras\ngrandes consiste en usar errores estándar *robustos* (**HAC** -\nheteroscedasticity and autocorrelation robust covariance matrix) al\nrealizar inferencia con la estimación de los parámetros.\n\n1.  las estimaciones serán insesgadas, consistentes pero ineficientes,\n\n2.  los residuos son los mismos y, por tanto, estarán autocorrelados,\n\n3.  pero la inferencia se realizará a partir de errores estándar robustos.\n\n"]},{"cell_type":"code","execution_count":1,"id":"142bc899-2d36-4e5e-b0f1-b9b0ab091de6","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["y = datosModelo3['dataLog']\nX = datosModelo3.iloc[:,1:-1]\nmodel5 = sm.OLS(y, X)\nresults5 = model5.fit()\nprint(results5.get_robustcov_results(cov_type='HAC', maxlags=3, use_correction=True).summary())"]},{"cell_type":"code","execution_count":1,"id":"c82db33b-568f-41b0-9ae8-7c0634bef645","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["repr_png(results5.get_robustcov_results(cov_type='HAC',\n                                        maxlags=3,\n                                        use_correction=True).summary().as_latex(), \"./img/lecc02/resultsModel5.png\")"]},{"cell_type":"markdown","id":"4d7a0bd2-43d4-4ae3-a614-7a513fcad8ef","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["-   **Covariance type**: HAC (heteroscedasticity and autocorrelation robust covariance matrix)\n\n<div>\n<img src=\"./img/lecc02/resultsModel5.png\" width=\"400\" class=\"center\"/>\n</div>\n\nEmpleando errores estándar robustos (HAC), podemos reducir el modelo\nde manera más cuidadosa usando desviaciones típicas robustas. El\nmodelo reducido es&#x2026;\n\n"]},{"cell_type":"code","execution_count":1,"id":"1c5be738-9605-4ea0-8ec3-6349084d9d48","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["y = datosModelo3['dataLog']\nX = datosModelo3.iloc[:,1:-1]\n\nsignificacion = 0.05\n\ninsignificant_feature = True\nwhile insignificant_feature:\n        results6      = sm.OLS(y, X).fit()\n        robustResults = results6.get_robustcov_results(cov_type='HAC', maxlags=3, use_correction=True)\n        robustPvalues = pd.Series(index=results6.pvalues.index, data=robustResults.pvalues)\n\n        significant = [p_value < significacion for p_value in robustPvalues]\n\n        \n        if all(significant):\n            insignificant_feature = False\n        else:\n            if X.shape[1] == 1:  # if there's only one insignificant variable left\n                print('No significant features found')\n                results6 = None\n                insignificant_feature = False\n            else:            \n                X = remove_most_insignificant(X, results6)\nprint(robustResults.summary())\nrepr_png(robustResults.summary().as_latex(), \"./img/lecc02/resultsModel6.png\")"]},{"cell_type":"markdown","id":"89f9300c-d014-45e9-be23-c070d7b4438a","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["<div>\n<img src=\"./img/lecc02/resultsModel6.png\" width=\"400\" class=\"center\"/>\n</div>\n\n-   Nótese que con HAC se aprecia que enero y octubre son significativos al 5%\n-   Pero la estimación MCO no es eficiente en presencia de auto-correlación\n\n"]},{"cell_type":"markdown","id":"930283a9-826f-4039-aa63-7866cb73b058","metadata":{"slideshow":{"slide_type":"slide"}},"source":["### Modelo del error\n\n"]},{"cell_type":"markdown","id":"c2f85b62-9675-4365-8148-d6c1e21efbec","metadata":{},"source":["En el modelo\n$\\boldsymbol{y}=\\boldsymbol{\\mathsf{X}\\beta}+\\boldsymbol{U},\\;$ cuando\nlas perturbaciones presentan heterocedasticidad y/o auto-correlación\n$$Var(\\boldsymbol{U}\\mid\\boldsymbol{\\mathsf{X}})=\\boldsymbol{\\Sigma}\\ne\\sigma^2\\boldsymbol{\\mathsf{I}},$$\npor tanto, el Teorema de Gauss-Markov ya no es válido. En esta\nsituación es posible explotar la estructura de la matriz\n$\\boldsymbol{\\Sigma}$ para minimizar la varianza del estimador.\n\nEn particular, el estimador lineal de mínima varianza es el estimador\nMCG (mínimos cuadrados generalizados)\n\n$$\\;\\widehat{\\boldsymbol{\\beta}}=(\\boldsymbol{\\mathsf{X'}}\\boldsymbol{\\mathsf{\\Sigma}}^{-1}\\boldsymbol{\\mathsf{X}})^{-1}\\boldsymbol{\\mathsf{X'}}\\boldsymbol{\\mathsf{\\Sigma}}^{-1}\\boldsymbol{y}\\;$$\n\nEl problema es que, en general, la matriz $\\boldsymbol{\\Sigma}$ es\ndesconocida.\n\nUna solución es aplicar un procedimiento iterativo en el que con los\nerrores de ajuste de una primera regresión que se estima la matriz\n$\\boldsymbol{\\Sigma}$. Con dicha matriz\n$\\widehat{\\boldsymbol{\\Sigma}}$ se re-estima el modelo por MCG&#x2026; con\nlos nuevos errores se re-estima $\\boldsymbol{\\Sigma}$&#x2026; que se usa\npara re-estimar el modelo por MCG&#x2026; y vuelta a empezar: con los\nnuevos errores&#x2026;\n\nEl algoritmo se detiene cuando las estimaciones convergen a valores\nestables.\n\n"]},{"cell_type":"markdown","id":"014d4c38-f9bb-424a-a322-25e1f4c37755","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["Cuando hicimos el Test de Breusch-Godfrey vimos que en la regresión\nauxiliar el primer retardo de los errores era significativo. Por\ntanto, vamos a indicar que las perturbaciones siguen un proceso AR(1).\nEl decir, vamos a estimar el modelo\n\n$$\\ln{y_t}=\\underbrace{\\beta_1+\\beta_2\\cdot t+\\beta_3\\cdot t^2}_{\\text{tendencia}} + \\underbrace{\\alpha_1 S_{t1} + \\alpha_3 S_{t3} + \\cdots + \\alpha_11 S_{t11}}_{\\text{comp. estacional}} + \\epsilon_t$$\n\ndonde las perturbaciones $\\boldsymbol{\\epsilon}=\\{\\epsilon_t\\}$ siguen\nel modelo\n\n$$\\epsilon_t = \\rho_1 \\epsilon_{t-1} + e_t$$\n\n(*en este caso la estimación (**GLSAR**) converge en 7 iteraciones*)\n\n"]},{"cell_type":"code","execution_count":1,"id":"54748177-9bfc-468e-a9e1-23798b165024","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["model = sm.GLSAR(y, X, rho=1) # :results silent rho=1 indica autocorrelación de orden uno\nfor i in range(7):\n    results = model.fit()\n    print(\"AR coefficients: {0}\".format(model.rho))\n    rho, sigma = sm.regression.yule_walker(results.resid,\n                                           order=model.order)\n    model = sm.GLSAR(y, X, rho)"]},{"cell_type":"code","execution_count":1,"id":"6810db47-a8d0-44ab-86cc-e144a31e673d","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["print(results.summary())"]},{"cell_type":"markdown","id":"b92b0806-2d1b-4cb4-842e-1cafc5b3eace","metadata":{"slideshow":{"slide_type":"subslide"}},"source":["<div>\n<img src=\"./img/lecc02/resultsModel7.png\" width=\"600\" class=\"center\"/>\n</div>\n\n"]},{"cell_type":"code","execution_count":1,"id":"ea094055-db88-4721-8209-cec45d06746f","metadata":{"slideshow":{"slide_type":"skip"}},"outputs":[],"source":["# este código realiza las mismas iteraciones que bloque de código de más arriba\nmodel2 = sm.GLSAR(y, X, rho=1)\nres = model2.iterative_fit(maxiter=7)\nmodel2.rho\nprint(model2.fit().summary())"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":5}