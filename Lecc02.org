#+TITLE: Econometría Aplicada. Lección 2
#+author: Marcos Bujosa
#+LANGUAGE: es-es

# +OPTIONS: toc:nil

#+EXCLUDE_TAGS: noexport

#+startup: shrink


#+LATEX_HEADER_EXTRA: \usepackage[spanish]{babel}
#+LATEX_HEADER_EXTRA: \usepackage{lmodern}
#+LATEX_HEADER_EXTRA: \usepackage{tabularx}
#+LATEX_HEADER_EXTRA: \usepackage{booktabs}
# +LATEX_HEADER: \hypersetup{colorlinks=true, linkcolor=blue}

#+LATEX: \maketitle

#+BEGIN_SRC emacs-lisp :exports none :results silent
(use-package ox-ipynb
  :load-path (lambda () (expand-file-name "ox-ipynb" scimax-dir)))
#+END_SRC

#+BEGIN_ABSTRACT
En esta lección veremos algunos modelos de regresión con series
temporales; en particular la estimación de componentes (no
observables) con modelos deterministas.
#+END_ABSTRACT

- [[https://mbujosab.github.io/EconometriaAplicada-SRC/Lecc02.html][lección en html]]
- [[https://mybinder.org/v2/gh/mbujosab/EconometriaAplicada-SRC/HEAD?labpath=Lecc02.ipynb][lección en mybinder]]


***  Carga de algunos módulos de python
   :PROPERTIES:
   :metadata: (slideshow . ((slide_type . skip)))
   :UNNUMBERED: t 
   :END:
   
#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results none
# Importamos algunos módulos de python
import numpy as np # linear algebra
import pandas as pd # dataframe processing
import statsmodels.api as sm  # modelos estadísticos
import matplotlib as mpl
import matplotlib.pyplot as plt # data visualization
# definimos parámetros para mejorar los gráficos
mpl.rc('text', usetex=True)
mpl.rc('text.latex', preamble=r'\usepackage{amsmath}')
<<<<<<< HEAD
from matplotlib import rcParams
rcParams['figure.figsize'] = 15,5
=======
import dataframe_image as dfi
import statsmodels.api as sm
>>>>>>> eab5f6c (modificacion en la generación de ficheros png)
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results none
# Usaré la siguiente función para transformar salidas en \LaTeX{} de statsmodels a ficheros png 
# que incluiré en las transparencias
from sympy.printing.preview import preview
def repr_png(tex, ImgFile):
    preamble = "\\documentclass[10pt,preview]{standalone}\n" \
        "\\usepackage{booktabs,amsmath,amsfonts}\\begin{document}"    
    preview(tex, filename=ImgFile, viewer='file', preamble=preamble, dvioptions=['-D','250'])
#+END_SRC


***** Datos                                                        :noexport:

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results replace silent output table
# import os
# for dirname, _, filenames in os.walk('./database'):
#     for filename in filenames:
#         print(os.path.join(dirname, filename))
#+END_SRC


**** Lectura datos: Internat. airline passengers. Monthly totals in thousands. Jan 49 – Dec 60
   :PROPERTIES:
   :metadata: (slideshow . ((slide_type . skip)))
   :UNNUMBERED: t 
   :END:


#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :exports code  :results silent
# Leemos los datos de un fichero csv y generamos un dataframe de pandas cuyo índice es el tiempo
OrigData = pd.read_csv('./database/Datasets-master/airline-passengers.csv')
OrigData['Month'] = pd.to_datetime(OrigData['Month'])
OrigData = OrigData.set_index(['Month'])
print(OrigData.head())
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :exports code  :results silent
# Creamos un dataframe con el mismo índice temporal de los datos originales pero con los datos en logaritmos
TransformedData = pd.DataFrame(index=OrigData.index)
TransformedData['dataLog'] = np.log(OrigData['Passengers'])
print(TransformedData.head())
#+END_SRC


* Descomposición estructural de una serie temporal
   :PROPERTIES:
   :metadata: (slideshow . ((slide_type . slide)))
   :END:

En la lección anterior vimos que una estrategia para analizar series
temporales es transformar los datos para

1) primero lograr que sean "*/estacionarios/*" y
2) después, mediante más transformaciones, lograr una secuencia de
   "*datos /i.i.d/*" (este segundo paso aún no lo hemos abordado)
#+LATEX:  \newline \noindent
(/recuerde que las expresiones "datos estacionarios" o "datos i.i.d." son un abuso del lenguaje/).

#+attr_ipynb: (slideshow . ((slide_type . subslide)))
#+LATEX: \medskip \noindent
Pero existe otro enfoque que pretende descomponer la serie temporal en
los siguientes componentes /"no observables"/ (o en un subconjunto de
ellos):

$$\boldsymbol{y} = \boldsymbol{t} + \boldsymbol{c} + \boldsymbol{s} + \boldsymbol{e}$$

#+LATEX: \noindent
donde:

- La tendencia "$\boldsymbol{t}$" :: recoge la lenta evolución de la
  media a /largo plazo/.

- El componente estacional "$\boldsymbol{s}$" :: recoge las
  oscilaciones periódicas que se repiten regularmente en ciclos
  estacionales (de año en año, o de semana en semana, etc.).

- El componente cíclico "$\boldsymbol{c}$" :: Cuando aparece
  explícitamente en el modelo, $\boldsymbol{c}$ recoge las
  oscilaciones a medio plazo. Es decir, aquellas de un plazo más largo
  que las oscilaciones estacionales, pero más corto que la tendencia
  de largo plazo. Si está ausente, dichas oscilaciones suelen aparecer
  en el componente de la tendencia, que entonces también podemos
  denominar /tendencia-ciclo/.

- El componente irregular "$\boldsymbol{e}$" :: recoge las
  oscilaciones no captadas por el resto de componentes, ya que debe
  cumplir la siguiente identidad: $\boldsymbol{e} = \boldsymbol{y} -
  \boldsymbol{t} - \boldsymbol{c} - \boldsymbol{s}$.

Ajuste aceptable si (como poco) el componente irregular
$\boldsymbol{e}$ parece "/estacionario/".


** Tendencia determinista /lineal/
   :PROPERTIES:
   :metadata: (slideshow . ((slide_type . slide)))
   :END:

#+NAME: ajuste-tendencia-lineal
#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python  :results silent
# Ajustamos por MCO una tendencia linea. 
# Para ello, primero creamos un DataFrame con el regresando y los regresores del modelo
datosModelo1 = TransformedData[['dataLog']].copy()
nsample = len(datosModelo1)
datosModelo1['cte'] = [1]*nsample
datosModelo1['time'] = np.linspace(1, nsample, nsample)
model1 = sm.OLS(datosModelo1['dataLog'], datosModelo1[['cte', 'time']])
results1 = model1.fit()
#+END_SRC

<<<<<<< HEAD
#+attr_ipynb: (slideshow . ((slide_type . skip)))
=======
#+attr_ipynb: (slideshow . ((slide_type . notes)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/airlinepass+linearTrend.png
import seaborn as sns
from matplotlib import rcParams
rcParams['figure.figsize'] = 15,5
plt.grid()  
ax = sns.regplot(x="time", y="dataLog", data=datosModelo1,
                 scatter_kws={"color": "black"}, line_kws={"color": "red"})
fig = ax.get_figure()
#fig.savefig("./img/airlinepass+linearTrend.png")
#+END_SRC


El modelo de tendencia más simple es la recta de regresión donde el
regresor es el propio índice $t$ que indica el instante del tiempo de
cada dato:

$$\ln{y_t}=\beta_1\cdot{1}+\beta_2\cdot t + e_t; \quad t=1:114$$

[[./img/airlinepass+linearTrend.png]]




#+attr_ipynb: (slideshow . ((slide_type . notes)))
#+NAME: Cte-ajuste-tendencia-lineal
#+BEGIN_SRC jupyter-python :results value :results silent
round(results1.params['cte'],4)
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . notes)))
#+NAME: Pte-ajuste-tendencia-lineal
#+BEGIN_SRC jupyter-python :results value :results silent
round(results1.params['time'],4)
#+END_SRC

#+name: my-latex-code
#+BEGIN_SRC latex :noweb strip-export :exports result :results raw
$$\widehat{\ln{y_t}}=<<Cte-ajuste-tendencia-lineal()>>+<<Pte-ajuste-tendencia-lineal()>>\cdot\big(t\big), \qquad t=1:114$$
#+END_SRC

#+RESULTS: my-latex-code
$$\widehat{\ln{y_t}}=4.8137+0.01\cdot\big(t\big), \qquad t=1:114$$


#+attr_ipynb: (slideshow . ((slide_type . notes)))
#+BEGIN_SRC jupyter-python :results file :file ./img/resultsModel1.png :results none
# print(results.summary()) Esta es la forma habitual de ver los resultados
repr_png(results1.summary().as_latex(),  "./img/resultsModel1.png") # pero emplearé esta para importar los resultados como imagen png en el material de clase
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . subslide)))
#+attr_org: :width 700
#+attr_html: :width 100px
#+attr_latex: :width 250px
[[./img/resultsModel1.png]]



#+attr_ipynb: (slideshow . ((slide_type . notes)))
#+BEGIN_SRC jupyter-python :results replace text/plain :exports results
results1.fittedvalues
results1.rsquared
print(results1.params)
#+END_SRC

#+RESULTS:
:RESULTS:
cte     4.813668
time    0.010048
dtype: float64
:END:


#+attr_ipynb: (slideshow . ((slide_type . notes)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/airlinepass+irreg.png 
ax = sns.lineplot(data=datosModelo1, x="time", y=results1.resid)
fig = ax.get_figure()
#fig.savefig("./img/airlinepass+irreg.png") 
#+END_SRC


#+attr_ipynb: (slideshow . ((slide_type . subslide)))

En este caso, el modelo 

$$\boldsymbol{y} = \boldsymbol{t} + \boldsymbol{e}$$

donde $\boldsymbol{t}$ es una tendencia lineal no es un ajuste
satisfactorio, pues el componente irregular $\boldsymbol{e}$ no parece
la realización de un proceso estacionario.


[[file:./img/airlinepass+irreg.png]]



#+attr_ipynb: (slideshow . ((slide_type . notes)))
>>>>>>> eab5f6c (modificacion en la generación de ficheros png)
#+BEGIN_SRC jupyter-python :results none
#Añadimos al DataFrame =datosModelo1= la tendencia ajustada, los residuos y la diferencia estacional de los residuos.
datosModelo1['yhat'] = datosModelo1['cte']*results1.params['cte']+datosModelo1['time']*results1.params['time']
datosModelo1['ehat'] = results1.resid
datosModelo1['ehatDiff12'] = datosModelo1['ehat'].diff(12)
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/lecc02/airlinepass+linearTrend.png
# Dibujamos los datos junto a la tendencia estimada
plt.plot(datosModelo1['dataLog'])
plt.plot(results1.fittedvalues)
plt.grid()  
plt.ylabel(r"Log-Passengers, ($\ln\boldsymbol{x}$) ")
#+END_SRC

<<<<<<< HEAD

El modelo de tendencia más simple es la recta de regresión (el
regresor no constante es el índice $t$):

$$\ln{y_t}=\underbrace{\beta_1+\beta_2\cdot t}_{\text{tendencia}} + e_t; \quad t=1:114$$
#+attr_ipynb: (slideshow . ((slide_type . fragment)))
#+attr_org: :width 800
#+attr_html: :width 900px
#+attr_latex: :width 425px
[[./img/lecc02/airlinepass+linearTrend.png]]

#+RESULTS: my-latex-code-linear-trend
:results:
$$\widehat{\ln{y_t}}=4.8137+0.01\cdot\big(t\big), \qquad t=1:114$$
:end:

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results none
print(results1.summary()) 
#+END_SRC


#+attr_ipynb: (slideshow . ((slide_type . subslide)))
#+attr_org: :width 600
#+attr_html: :width 600px
#+attr_latex: :width 300px
[[./img/lecc02/resultsModel1.png]]



#+attr_ipynb: (slideshow . ((slide_type . subslide)))
*_Componente irregular_*
#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/lecc02/airlinepass+irreg.png
# Gráfico de los residuos del ajuste.
plt.grid()  
plt.plot(results1.resid)
#+END_SRC

#+attr_org: :width 800
#+attr_html: :width 900px
#+attr_latex: :width 425px
[[file:./img/lecc02/airlinepass+irreg.png]]

En este caso, el modelo 

$$\boldsymbol{y} = \boldsymbol{t} + \boldsymbol{e}$$

@@latex:\noindent@@ donde $\boldsymbol{t}$ es una tendencia lineal no
es un ajuste satisfactorio, pues el /componente irregular/
$$\boldsymbol{e}=\boldsymbol{y}-\boldsymbol{t}$$
no tiene la apariencia de realización de un proceso estacionario.


#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results file silent  :file ./img/lecc02/airlinepass+irregDiff12.png 
# Gráfico de la diferencia estacional de los residuos del ajuste.
plt.grid()  
plt.plot(datosModelo1['ehatDiff12'])
=======
#+attr_ipynb: (slideshow . ((slide_type . notes)))
#+BEGIN_SRC jupyter-python :results file silent  :file ./img/airlinepass+irregDiff12.png 
ax = sns.lineplot(data=datosModelo1, x="time", y=datosModelo1['ehatDiff12'])
fig = ax.get_figure()
#fig.savefig("./img/airlinepass+irregDiff12.png")
>>>>>>> eab5f6c (modificacion en la generación de ficheros png)
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . subslide)))
Adicionalmente podemos ver que diferencia de orden 12 del componente
irregular parece mostrar un componente cíclico con un periodo de unos
4 años.

#+attr_org: :width 800
#+attr_html: :width 900px
#+attr_latex: :width 425px
[[file:./img/lecc02/airlinepass+irregDiff12.png]]

En el siguiente ejercicio probaremos con una tendencia cuadrática...


**************  Codigo aux                                       :noexport:

#+attr_ipynb: (slideshow . ((slide_type . notes)))
~Los siguientes bloques de código muestran el valor de los parámetros estimados por MCO en el anterior modelo.~
#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+NAME: Cte-ajuste-tendencia-lineal
#+BEGIN_SRC jupyter-python :results value :results silent :exports results 
round(results1.params['cte'],4)
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+NAME: Pte-ajuste-tendencia-lineal
#+BEGIN_SRC jupyter-python :results value :results silent :exports results 
round(results1.params['time'],4)
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . notes)))
El siguiente código escribe la ecuación en \LaTeX{} con el valor de
los parámetros estimados por MCO desde el fichero =orgmode=
#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+name: my-latex-code-linear-trend
#+BEGIN_SRC latex :noweb strip-export :exports result :results  drawer replace
$$\widehat{\ln{y_t}}=<<Cte-ajuste-tendencia-lineal()>>+<<Pte-ajuste-tendencia-lineal()>>\cdot\big(t\big), \qquad t=1:114$$
#+END_SRC


#+attr_ipynb: (slideshow . ((slide_type . notes)))
Generamos un fichero =png= con los resultados de la estimación MCO.
#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results silent file :file ./img/lecc02/resultsModel1.png 
# print(results.summary()) Esta es la forma habitual de ver los resultados
repr_png(results1.summary().as_latex(),  "./img/lecc02/resultsModel1.png") # pero emplearé esta para importar los resultados como imagen png en el material de clase
#+END_SRC



** Tendencia determinista /cuadrática/
   :PROPERTIES:
   :metadata: (slideshow . ((slide_type . slide)))
   :END:

<<<<<<< HEAD
#+attr_ipynb: (slideshow . ((slide_type . skip)))
=======

#+attr_ipynb: (slideshow . ((slide_type . notes)))
>>>>>>> eab5f6c (modificacion en la generación de ficheros png)
#+NAME: ajuste-tendencia-cuadratica
#+BEGIN_SRC jupyter-python  :results silent
# creamos un DataFrame con el regresando y los regresores del modelo.
datosModelo2 = TransformedData[['dataLog']].copy()
nsample = len(datosModelo1)
datosModelo2['cte'] = [1]*nsample
datosModelo2['time'] = np.linspace(1, nsample, nsample)
datosModelo2['sq_time'] = [t**2 for t in datosModelo2['time']]
# Ajustamos por MCO una tendencia cuadrática a los datos.
model2 = sm.OLS(datosModelo1['dataLog'], datosModelo2[['cte', 'time', 'sq_time']])
results2 = model2.fit()
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results none
# Añadimos al DataFrame 'datosModelo2' la tendencia ajustada, los residuos y la diferencia estacional de los residuos.
datosModelo2['yhat'] = results2.fittedvalues
datosModelo2['ehat'] = results2.resid
datosModelo2['ehatDiff12'] = datosModelo2['ehat'].diff(12)
#+END_SRC

<<<<<<< HEAD
#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/lecc02/airlinepass+quadraticTrend.png
# Dibujamos los datos junto a la tendencia estimada.
plt.plot(datosModelo1['dataLog'])
plt.plot(results2.fittedvalues)
plt.grid()  
plt.ylabel(r"Log-Passengers, ($\ln\boldsymbol{x}$) ")
=======

#+attr_ipynb: (slideshow . ((slide_type . notes)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/airlinepass+quadraticTrend.png
ax = sns.lineplot(data=datosModelo2, x="time", y="dataLog")
ax = sns.lineplot(data=datosModelo2, x="time", y="yhat")
fig = ax.get_figure()
#fig.savefig("./img/airlinepass+quadraticTrend.png")
>>>>>>> eab5f6c (modificacion en la generación de ficheros png)
#+END_SRC

$$\ln{y_t}=\underbrace{\beta_1+\beta_2\cdot t + \beta_3\cdot t^2}_{\text{tendencia}} + e_t; \quad t=1:114$$

#+attr_ipynb: (slideshow . ((slide_type . fragment)))
#+attr_org: :width 800
#+attr_html: :width 900px
#+attr_latex: :width 425px
[[./img/lecc02/airlinepass+quadraticTrend.png]]

#+RESULTS: my-latex-code-quadratic-trend
:results:
$$\widehat{\ln{y_t}}=4.7364+(0.0132)\cdot t +(-2.191e-05)\cdot t^2, \qquad t=1:114$$
:end:

 

<<<<<<< HEAD
#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/lecc02/resultsModel2.png
print(results2.summary()) 
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . subslide)))
#+attr_org: :width 600
#+attr_html: :width 600px
#+attr_latex: :width 300px
[[./img/lecc02/resultsModel2.png]]
=======

#+attr_ipynb: (slideshow . ((slide_type . notes)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/resultsModel2.png
# print(results.summary()) Esta es la forma habitual de ver los resultados
repr_png(results2.summary().as_latex(), "./img/resultsModel2.png") # pero usaré esta
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . subslide)))
#+attr_org: :width 700
#+attr_html: :width 100px
#+attr_latex: :width 250px
[[./img/resultsModel2.png]]




#+attr_ipynb: (slideshow . ((slide_type . notes)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/airlinepass+irreg2.png
ax = sns.lineplot(data=datosModelo2, x="time", y=results2.resid)
fig = ax.get_figure()
#fig.savefig("./img/airlinepass+irreg2.png")
#+END_SRC
>>>>>>> eab5f6c (modificacion en la generación de ficheros png)


#+attr_ipynb: (slideshow . ((slide_type . subslide)))
*_Componente irregular_*
#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/lecc02/airlinepass+irreg2.png
plt.grid()  
plt.plot(results2.resid)
#+END_SRC

#+attr_org: :width 800
#+attr_html: :width 900px
#+attr_latex: :width 425px
[[./img/lecc02/airlinepass+irreg2.png]]

De manera análoga al caso anterior, el modelo

$$\boldsymbol{y} = \boldsymbol{t} + \boldsymbol{e}$$

@@latex:\noindent@@ donde $\boldsymbol{t}$ ahora es una /tendencia
cuadrática/ tampoco es un ajuste satisfactorio, pues el componente
irregular $\boldsymbol{e}$ sigue sin parecerse a la realización de un
proceso estacionario.


<<<<<<< HEAD
#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/lecc02/airlinepass+irregDiff12-2.png
plt.grid()  
plt.plot(datosModelo2['ehatDiff12'])
=======
#+attr_ipynb: (slideshow . ((slide_type . notes)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/airlinepass+irregDiff12-2.png
ax = sns.lineplot(data=datosModelo2, x="time", y=datosModelo2['ehatDiff12'])
fig = ax.get_figure()
#fig.savefig("./img/airlinepass+irregDiff12-2.png")
>>>>>>> eab5f6c (modificacion en la generación de ficheros png)
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . subslide)))

También en este modelo la diferencia de orden 12 del componente
irregular muestra un componente cíclico con un periodo de unos 4 años.

#+attr_org: :width 800
#+attr_html: :width 900px
#+attr_latex: :width 425px
[[file:./img/lecc02/airlinepass+irregDiff12.png]]

Para obtener una /tendencia-ciclo/ que capte este ciclo, son
necesarios procedimientos más sofisticados (por ejemplo TRAMO-SEATS, o
X13-ARIMA, o STAMP, o LDHR, o E4, etc.) que estiman tendencias y
componentes estacionales estocásticos.

#+attr_ipynb: (slideshow . ((slide_type . fragment)))
En el siguiente ejercicio estimaremos un *componente estacional
determinista* (junto a una tendencia cuadrática determinista).

**************  Codigo aux                                       :noexport:

#+attr_ipynb: (slideshow . ((slide_type . notes)))
Los siguientes bloques de código muestran el valor de los parámetros
estimados por MCO.
#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+NAME: Cte-ajuste-tendencia-cuadr
#+BEGIN_SRC jupyter-python :results value :results silent :exports results 
round(results2.params['cte'],4)
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+NAME: beta2-tendencia-cuadr
#+BEGIN_SRC jupyter-python :results value :results silent :exports results 
round(results2.params['time'],4)
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+NAME: beta3-tendencia-cuadr
#+BEGIN_SRC jupyter-python :results value :results silent :exports results 
round(results2.params['sq_time'],8)
#+END_SRC


#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+name: my-latex-code-quadratic-trend
#+BEGIN_SRC latex :noweb strip-export :exports result :results drawer replace
$$\widehat{\ln{y_t}}=<<Cte-ajuste-tendencia-cuadr()>>+(<<beta2-tendencia-cuadr()>>)\cdot t +(<<beta3-tendencia-cuadr()>>)\cdot t^2, \qquad t=1:114$$
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/lecc02/resultsModel2.png
repr_png(results2.summary().as_latex(), "./img/lecc02/resultsModel2.png") 
#+END_SRC


** Tendencia cuadrática más estacionalidad determinista mediante /dummies/
   :PROPERTIES:
   :metadata: (slideshow . ((slide_type . slide)))
   :END:

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results silent
# Creamos un dataframe con los datos y los regresores 'cte', 't' y 't^2'
df = TransformedData[['dataLog']].copy()
nsample = len(df)
df['cte']     = [1]*nsample
df['time']    = np.linspace(1, nsample, nsample)
df['sq_time'] = [t**2 for t in df['time']]
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results none
# Creamos las /dummies/ estacionales
from statsmodels.tsa.deterministic import Seasonality
seas_gen = Seasonality(12, initial_period=1)
seasonalDummies = seas_gen.in_sample(df.index)
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results none
# Creamos un dataframe con el regresando y todos los regresores del modelo
datosModelo3 = pd.concat([df, seasonalDummies],axis=1)
# realizamos la regresión de la primera columna ('dataLog') sobre el resto de columnas del dataframe.
model3 = sm.OLS(datosModelo3['dataLog'], datosModelo3.iloc[:,1:-1])
results3 = model3.fit()
#+END_SRC


#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results none
# La combinación lineal de los regresores 'cte', 'time' y 'sq_time' usando los correspondientes
# parámetros estimados nos da el componente de tendencia (determinista) estimado. 
TrendComp = datosModelo3[['cte','time','sq_time']].dot(results3.params[['cte','time','sq_time']])
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/lecc02/airlinepass+TrendC.png
rcParams['figure.figsize'] = 15,4
plt.plot(datosModelo1['dataLog'])
plt.plot(TrendComp)
plt.grid()  
plt.ylabel(r"Log-Passengers, ($\ln\boldsymbol{x}$) ")
#+END_SRC

#+attr_org: :width 800
#+attr_html: :width 900px
#+attr_latex: :width 425px
[[./img/lecc02/airlinepass+TrendC.png]]

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/lecc02/airlinepass+SeasonalC.png
SeasonalComp = (seasonalDummies.iloc[:,:-1]).dot(results3.params[3:])
plt.grid()  
plt.plot(SeasonalComp)
#+END_SRC

#+attr_org: :width 800
#+attr_html: :width 900px
#+attr_latex: :width 425px
[[file:./img/lecc02/airlinepass+SeasonalC.png]]


*** Ajuste y componente irregular $\boldsymbol{e}=\boldsymbol{y}-\boldsymbol{t}-\boldsymbol{s}$
   :PROPERTIES:
   :metadata: (slideshow . ((slide_type . subslide)))
   :END:


#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/lecc02/airlinepass+yhat.png
plt.grid()  
plt.plot(datosModelo3['dataLog'])
plt.plot(TrendComp + SeasonalComp)
#+END_SRC

#+attr_org: :width 800
#+attr_html: :width 900px
#+attr_latex: :width 425px
[[./img/lecc02/airlinepass+yhat.png]]

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/lecc02/airlinepass+IrregC.png
plt.grid()  
plt.plot(results3.resid)
#+END_SRC

#+attr_org: :width 800
#+attr_html: :width 900px
#+attr_latex: :width 425px
[[./img/lecc02/airlinepass+IrregC.png]]


*** Valoración de modelos con componentes deterministas
   :PROPERTIES:
   :metadata: (slideshow . ((slide_type . subslide)))
   :END:

- Estos modelos resultan útiles para realizar un análisis descriptivo.
 
- Pero suelen funcionar bastante mal como herramienta de predicción:

  - no tienen en cuenta la dependencia inter-temporal de los datos (se
    han estimado mediante una regresión como si los datos hubieran
    sido de sección cruzada)

  - Por ejemplo, a la hora de prever el dato de enero de 1961, en este
    modelo pesa tanto el dato de enero de 1949 como el dato de enero
    de 1960.

En general, para que los modelos funcionen bien en predicción deben
/dar un mayor peso a los datos recientes/ frente a los datos alejados
en el tiempo.
@@latex:\smallskip@@

Pero sigamos explorando este modelo...
@@latex:\bigskip@@

#+attr_ipynb: (slideshow . ((slide_type . subslide)))
*Hay parámetros no significativos...* (p-valores para dummies enero,
febrero y octubre).

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results file :file ./img/lecc02/resultsModel3.png :results silent
repr_png(results3.summary().as_latex(), "./img/lecc02/resultsModel3.png")
#+END_SRC

#+BEGIN_EXPORT latex
\begin{center}
  \includegraphics[width=.55\textwidth]{./img/lecc02/resultsModel3.png}
\end{center}
#+END_EXPORT

# +attr_ipynb: (slideshow . ((slide_type . fragment)))
# +attr_org: :width 600
# +attr_html: :width 100px
# +attr_latex: :width 250px
# [[./img/lecc02/resultsModel3.png]]

#+attr_ipynb: (slideshow . ((slide_type . fragment)))
#+BEGIN_EXPORT html
<div>
<img src="./img/lecc02/resultsModel3.png" width="400" class="center"/>
</div>
#+END_EXPORT

@@latex:\bigskip@@

#+attr_ipynb: (slideshow . ((slide_type . subslide)))
*podemos eliminarlos secuencialmente* (quitando cada vez la variable de mayor p-valor)
#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results none
import operator
def remove_most_insignificant(df, results):
    # use operator to find the key which belongs to the maximum value in the dictionary:
    max_p_value = max(results.pvalues.items(), key=operator.itemgetter(1))[0]
    # this is the feature you want to drop:
    df.drop(columns = max_p_value, inplace = True)
    return df
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results none
y = datosModelo3['dataLog']
X = datosModelo3.iloc[:,1:-1]
significacion = 0.05
insignificant_feature = True
while insignificant_feature:
        model4 = sm.OLS(y, X)
        results4 = model4.fit()
        significant = [p_value < significacion for p_value in results4.pvalues]
        if all(significant):
            insignificant_feature = False
        else:
            if X.shape[1] == 1:  # if there's only one insignificant variable left
                print('No significant features found')
                results4 = None
                insignificant_feature = False
            else:            
                X = remove_most_insignificant(X, results4)

print(results4.summary())
#+END_SRC


#+BEGIN_EXPORT latex
\begin{center}
  \includegraphics[width=.55\textwidth]{./img/lecc02/resultsModel4.png}
\end{center}
#+END_EXPORT

# +attr_ipynb: (slideshow . ((slide_type . skip)))
# +attr_org: :width 600
# +attr_html: :width 100px
# +attr_latex: :width 250px
# [[file:./img/lecc02/resultsModel4.png]]

#+attr_ipynb: (slideshow . ((slide_type . fragment)))
#+BEGIN_EXPORT html
<div>
<img src="./img/lecc02/resultsModel4.png" width="400" class="center"/>
</div>
#+END_EXPORT

@@latex:\bigskip@@

Pero esta inferencia es incorrecta. Con auto-correlación la varianza
del estimador MCO es diferente (*la estimación por defecto de las
desviaciones típicas es incorrecta*)

**************  Codigo aux                                       :noexport:

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/lecc02/resultsModel4.png
repr_png(results4.summary().as_latex(), "./img/lecc02/resultsModel4.png") 
#+END_SRC



* Perturbaciones no esféricas
   :PROPERTIES:
   :metadata: (slideshow . ((slide_type . slide)))
   :END:

# [[https://www.statsmodels.org/dev/diagnostic.html]]

Considere el modelo
$\boldsymbol{y}=\boldsymbol{\mathsf{X}\beta}+\boldsymbol{U}.\;$ Bajo
los supuestos habituales

$$E(\boldsymbol{U}\mid\boldsymbol{\mathsf{X}})=\boldsymbol{0},\quad
Var(\boldsymbol{U}\mid\boldsymbol{\mathsf{X}})=\sigma^2\boldsymbol{\mathsf{I}}\quad
\text{y} \quad E(\boldsymbol{\mathsf{X'X}}) \text{ es invertible}$$

@@latex:\noindent@@ el estimador
$\;\widehat{\boldsymbol{\beta}}=(\boldsymbol{\mathsf{X'X}})^{-1}\boldsymbol{\mathsf{X'}Y}\;$
es insesgado y eficiente, con varianza

$$\;Var(\widehat{\boldsymbol{\beta}}\mid\boldsymbol{\mathsf{X}})=\sigma^2(\boldsymbol{\mathsf{X'X}})^{-1}$$

@@latex:\medskip@@

#+attr_ipynb: (slideshow . ((slide_type . fragment)))
Pero si las perturbaciones $\boldsymbol{U}$ del modelo son
heterocedásticas y/o autocorreladas
$$Var(\boldsymbol{U}\mid\boldsymbol{\mathsf{X}})=\boldsymbol{\Sigma}\ne\sigma^2\boldsymbol{\mathsf{I}}$$
entonces el estimador $\widehat{\boldsymbol{\beta}}$, aunque
insesgado, ya no es eficiente; y su varianza es

$$Var(\widehat{\boldsymbol{\beta}}\mid\boldsymbol{\mathsf{X}})=Var(\widehat{\boldsymbol{\beta}}-\boldsymbol{\mathsf{I}}\boldsymbol{\beta}\mid\boldsymbol{\mathsf{X}})=
(\boldsymbol{\mathsf{X'X}})^{-1}\boldsymbol{\mathsf{X'}}
\boldsymbol{\Sigma}
\boldsymbol{\mathsf{X}}(\boldsymbol{\mathsf{X'X}})^{-1}.$$
@@latex:\medskip@@

** Test de autocorrelación de Breusch y Godfrey
   :PROPERTIES:
   :metadata: (slideshow . ((slide_type . subslide)))
   :END:

El tests el de Breusch y Godfrey (y el de Durbin-Watson) contrastan la $H_0$ de /no autocorrelación/.

#+attr_ipynb: (slideshow . ((slide_type . fragment)))
@@latex:\noindent@@
Considere el /modelo de regresión lineal/ 

#+name: ModeloRegresionLineal
\begin{equation}
Y_t = \beta_1+ \beta_2 X_{t,1} + \cdots +  \beta_k X_{t,k+1} + U_t 
\end{equation}
# \label{eq:ModeloRegresionLineal}

@@latex:\noindent@@
donde las perturbaciones $\boldsymbol{U}$ quizá siguen un esquema
auto-regresivo $AR(p)$:
# $\boldsymbol{U}=\{U_t \mid t\in \mathbb{Z}\}$

$$U_t = \rho_1 U_{t-1} + \rho_2 U_{t-2}  + \cdots + \rho_p U_{t-p} + \varepsilon_t$$
- *Paso 1*. Obtener los errores $\hat{\boldsymbol{e}}$ del ajuste MCO
  del modelo ([[ModeloRegresionLineal]]) con una muestra de tamaño $T$.
  # \ref{eq:ModeloRegresionLineal}
- *Paso 2*. Calcular el $R^2$ de la /regresión auxiliar/ de los
  errores $\hat{\boldsymbol{e}}$ sobre los regresores del modelo
  original ([[ModeloRegresionLineal]]) y sobre los $p$ primeros retardos
  de $\hat{\boldsymbol{e}}$.  $$\hat{e}_t = \alpha_0 + \alpha_1
  X_{t,1} + \cdots \alpha_k X_{t,k} + \rho_1 \hat{e}_{t-1} + \rho_2
  \hat{e}_{t-2} + \cdots + \rho_p \hat{e}_{t-p} + \varepsilon_t$$
  #  

Asintóticamente y bajo la $H_0$ de /no autocorrelación/: $\quad\rho_i = 0\text{ para todo }i$

$$n R^2\,\sim\,\chi^2_p,$$

@@latex:\noindent@@
donde $R^2$ es el coeficiente de determinación de la regresión
auxiliar y $n=T-p$.
@@latex:\medskip@@

#+attr_ipynb: (slideshow . ((slide_type . notes)))
*El test de Durbin-Watson* contrasta la autocorrelación _de orden
uno_. Para muestras grandes, el test es aproximadamente igual a
$2(1-{\hat {\rho }})$, donde ${\hat{\rho}}$ es la autocorrelación de
orden uno de los residuos. Por tanto, valores del test próximos a 2
indican no autocorrelación, valores próximos a 0 indican fuerte
autocorrelación positiva y valores próximos a 4 indican fuerte
autocorrelación negativa.

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python  :results silent
import statsmodels.stats.diagnostic as dg
#perform Breusch-Godfrey test of order p = 3
arbg = dg.acorr_breusch_godfrey(results4, nlags=3, store=True)
arbg[:1]
repr_png(arbg[-1].resols.summary().as_latex(), "./img/lecc02/resultsBreusch-Godfrey.png") 
#+END_SRC

#+BEGIN_EXPORT latex
\begin{center}
  \includegraphics[width=.55\textwidth]{./img/lecc02/resultsBreusch-Godfrey.png}
\end{center}
#+END_EXPORT

# +attr_ipynb: (slideshow . ((slide_type . skip)))
# +attr_org: :width 600
# +attr_html: :width 100px
# +attr_latex: :width 250px
# [[./img/lecc02/resultsBreusch-Godfrey.png]]


#+attr_ipynb: (slideshow . ((slide_type . subslide)))


#+label: Test-Breusch-Godfrey
#+RESULTS: my-latex-code-Breusch-Godfrey
:results:
- Valor del estadístico: $\quad 62.7119\qquad$ (p-valor: $\; 1.55e-13$)
- $x_{12}$ corresponde al primer retardo en la regresión auxiliar y es muy significativo
:end:

#+BEGIN_EXPORT html
<div>
<img src="./img/lecc02/resultsBreusch-Godfrey.png" width="450" class="center"/>
</div>
#+END_EXPORT

**************  Codigo aux                                       :noexport:

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+name: my-latex-code-Breusch-Godfrey
#+BEGIN_SRC latex :noweb strip-export :exports result :results drawer
- Valor del estadístico: $\quad <<Breusch-Godfrey test value()>>\qquad$ (p-valor: $\; <<Breusch-Godfrey test p-value()>>$)
- $x_{12}$ corresponde al primer retardo en la regresión auxiliar y es muy significativo
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+NAME: Breusch-Godfrey test value
#+BEGIN_SRC jupyter-python  :results value :results silent :exports results 
# valor del estadístico del test
round(arbg[0], 4)
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+NAME: Breusch-Godfrey test p-value
#+BEGIN_SRC jupyter-python  :results value :results silent :exports results 
# pvalor del test
round(arbg[1], 15)
#+END_SRC


** Errores estándar robustos
   :PROPERTIES:
   :metadata: (slideshow . ((slide_type . slide)))
   :END:


<<<<<<< HEAD
Un procedimiento adecuado en presencia de autocorrelación y muestras
grandes consiste en usar errores estándar /robustos/ (*HAC* -
heteroscedasticity and autocorrelation robust covariance matrix) al
realizar inferencia con la estimación de los parámetros.

1) las estimaciones serán insesgadas, consistentes pero ineficientes,

2) los residuos son los mismos y, por tanto, estarán autocorrelados, aunque

3) la inferencia a partir de errores estándar robustos será válida

# https://stats.stackexchange.com/questions/523952/estimate-hac-covariance-matrix-from-data-by-hand-newey-west

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results silent
y = datosModelo3['dataLog']
X = datosModelo3.iloc[:,1:-1]
model5 = sm.OLS(y, X)
results5 = model5.fit()
print(results5.get_robustcov_results(cov_type='HAC', maxlags=3, use_correction=True).summary())
#+END_SRC

 
#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/lecc02/resultsModel5.png
repr_png(results5.get_robustcov_results(cov_type='HAC', maxlags=3, use_correction=True).summary().as_latex(), "./img/lecc02/resultsModel5.png")
#+END_SRC

#+BEGIN_EXPORT latex
\begin{center}
  \includegraphics[width=.55\textwidth]{./img/lecc02/resultsModel5.png}
\end{center}
#+END_EXPORT

# +attr_ipynb: (slideshow . ((slide_type . skip)))
# +attr_org: :width 600
# +attr_html: :width 100px
# +attr_latex: :width 250px
# [[./img/lecc02/resultsModel5.png]]

#+attr_ipynb: (slideshow . ((slide_type . subslide)))
- *Covariance type*: HAC (heteroscedasticity and autocorrelation robust covariance matrix)
#+BEGIN_EXPORT html
<div>
<img src="./img/lecc02/resultsModel5.png" width="400" class="center"/>
</div>
#+END_EXPORT

Ahora, y empleando errores estándar robustos (HAC), podemos reducir el
modelo de manera más cuidadosa usando desviaciones típicas
robustas. El modelo reducido es...


#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/lecc02/resultsModel6.png
y = datosModelo3['dataLog']
X = datosModelo3.iloc[:,1:-1]

significacion = 0.05

insignificant_feature = True
while insignificant_feature:
        results6      = sm.OLS(y, X).fit()
        robustResults = results6.get_robustcov_results(cov_type='HAC', maxlags=3, use_correction=True)
        robustPvalues = pd.Series(index=results6.pvalues.index, data=robustResults.pvalues)

        significant = [p_value < significacion for p_value in robustPvalues]

        
        if all(significant):
            insignificant_feature = False
        else:
            if X.shape[1] == 1:  # if there's only one insignificant variable left
                print('No significant features found')
                results6 = None
                insignificant_feature = False
            else:            
                X = remove_most_insignificant(X, results6)
print(robustResults.summary())
repr_png(robustResults.summary().as_latex(), "./img/lecc02/resultsModel6.png") 
#+END_SRC

#+BEGIN_EXPORT latex
\begin{center}
  \includegraphics[width=.55\textwidth]{./img/lecc02/resultsModel6.png}
\end{center}
#+END_EXPORT


#+attr_ipynb: (slideshow . ((slide_type . subslide)))
#+BEGIN_EXPORT html
<div>
<img src="./img/lecc02/resultsModel6.png" width="400" class="center"/>
</div>
#+END_EXPORT
- Nótese que ahora (HAC) se aprecia que enero y octubre son significativos al 5%
- Pero la estimación MCO no es eficiente en presencia de auto-correlación


**************  Codigo aux                                       :noexport:

# [[https://towardsdatascience.com/solving-autocorrelation-problems-in-general-linear-model-on-a-real-world-application-0bd3eeda20a1]]

# [[https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.GLSAR.html]]

** Modelo del error
   :PROPERTIES:
   :metadata: (slideshow . ((slide_type . slide)))
   :END:

En el modelo
$\boldsymbol{y}=\boldsymbol{\mathsf{X}\beta}+\boldsymbol{U},\;$ si las
perturbaciones presentan heterocedasticidad y/o auto-correlación, y
por tanto
$$Var(\boldsymbol{U}\mid\boldsymbol{\mathsf{X}})=\boldsymbol{\Sigma}\ne\sigma^2\boldsymbol{\mathsf{I}},$$
el Teorema de Gauss-Markov ya no es válido, ya que es posible explotar
la estructura de la matriz $\boldsymbol{\Sigma}$ para minimizar la
varianza del estimador.

# https://mbujosab.github.io/CursoDeAlgebraLineal/libro.pdf#section.alph6.18.Alph1

En particular, el estimador lineal de mínima varianza es el estimador
MCG (mínimos cuadrados generalizados)

$$\;\widehat{\boldsymbol{\beta}}=(\boldsymbol{\mathsf{X'}}\boldsymbol{\mathsf{\Sigma}}^{-1}\boldsymbol{\mathsf{X}})^{-1}\boldsymbol{\mathsf{X'}}\boldsymbol{\mathsf{\Sigma}}^{-1}\boldsymbol{y}\;$$

El problema es que, en general, la matriz $\boldsymbol{\Sigma}$ es
desconocida.

Una solución es aplicar un procedimiento iterativo en el que se estima
la matriz $\boldsymbol{\Sigma}$ empleando los errores del ajuste de
una primera regresión. Con dicha matriz
$\widehat{\boldsymbol{\Sigma}}$ se re-estima el modelo por MCG... con
los nuevos errores se re-estima $\boldsymbol{\Sigma}$... y vuelta a
empezar...

El algoritmo se detiene cuando las estimaciones convergen a valores
estables.

#+attr_ipynb: (slideshow . ((slide_type . subslide)))
Cuando realizamos el Test de Breusch-Godfrey vimos que en la regresión
auxiliar el primer retardo de los errores era significativo. Por
tanto, vamos a indicar que las perturbaciones siguen un proceso AR(1).
El decir, vamos a estimar el modelo

$$\ln{y_t}=\underbrace{\beta_1+\beta_2\cdot t+\beta_3\cdot t^2}_{\text{tendencia}} + \underbrace{\alpha_1 S_{t1} + \alpha_3 S_{t3} + \cdots + \alpha_11 S_{t11}}_{\text{comp. estacional}} + \epsilon_t$$

donde las perturbaciones $\boldsymbol{\epsilon}=\{\epsilon_t\}$ siguen
el modelo

$$\epsilon_t = \rho_1 \epsilon_{t-1} + e_t$$

(/en este caso la estimación (*GLSAR*) converge en 7 iteraciones/)

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results silent :file ./img/lecc02/resultsModel7.png
model = sm.GLSAR(y, X, rho=1) # rho=1 indica autocorrelación de orden uno
for i in range(7):
    results = model.fit()
    print("AR coefficients: {0}".format(model.rho))
    rho, sigma = sm.regression.yule_walker(results.resid,
                                           order=model.order)
    model = sm.GLSAR(y, X, rho)
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results none
print(results.summary())
#+END_SRC

#+BEGIN_EXPORT latex
\begin{center}
  \includegraphics[width=.55\textwidth]{./img/lecc02/resultsModel7.png}
\end{center}
#+END_EXPORT

# +attr_ipynb: (slideshow . ((slide_type . skip)))
# +attr_org: :width 600
# +attr_html: :width 100px
# +attr_latex: :width 250px
# [[./img/lecc02/resultsModel7.png]]

#+attr_ipynb: (slideshow . ((slide_type . subslide)))
#+BEGIN_EXPORT html
<div>
<img src="./img/lecc02/resultsModel7.png" width="600" class="center"/>
</div>
#+END_EXPORT




#+attr_ipynb: (slideshow . ((slide_type . skip)))
#+BEGIN_SRC jupyter-python :results none
# este código realiza las mismas iteraciones que bloque de código de más arriba
model2 = sm.GLSAR(y, X, rho=1)
res = model2.iterative_fit(maxiter=7)
model2.rho
print(model2.fit().summary())
#+END_SRC


**************  Codigo aux                                       :noexport:

#+attr_ipynb: (slideshow . ((slide_type . notes)b))
#+BEGIN_SRC jupyter-python :results file silent :file ./img/lecc02/resultsModel7.png
repr_png(results.summary().as_latex(), "./img/lecc02/resultsModel7.png") 
#+END_SRC


# [[https://ninjakx.github.io/Introduction-to-Time-series/]]

# [[https://www.kaggle.com/code/darpan25bajaj/air-passengers-forecasting]]

# [[https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/]]

=======
#+attr_ipynb: (slideshow . ((slide_type . notes)))
#+NAME: ajuste-tendencia-cuadratica
#+BEGIN_SRC jupyter-python  :results silent
datosModelo3 = TransformedData[['dataLog']].copy()
nsample = len(datosModelo1)
datosModelo3['cte'] = [1]*nsample
datosModelo3['time'] = np.linspace(1, nsample, nsample)
datosModelo3['sq_time'] = [t**2 for t in datosModelo3['time']]
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . notes)))
Creamos las /dummies/ estacionales
#+attr_ipynb: (slideshow . ((slide_type . notes)))
#+BEGIN_SRC jupyter-python
from statsmodels.datasets import sunspots
from statsmodels.tsa.deterministic import Seasonality
seas_gen = Seasonality(12, initial_period=1)
seas_gen.in_sample(datosModelo3.index)
#+END_SRC


#+attr_ipynb: (slideshow . ((slide_type . notes)))
#+NAME: ajuste-tendencia-cuadratica
#+BEGIN_SRC jupyter-python  :results silent
datosModelo2 = TransformedData[['dataLog']].copy()
nsample = len(datosModelo1)
datosModelo2['cte'] = [1]*nsample
datosModelo2['time'] = np.linspace(1, nsample, nsample)
datosModelo2['sq_time'] = [t**2 for t in datosModelo2['time']]
model2 = sm.OLS(datosModelo1['dataLog'], datosModelo2[['cte', 'time', 'sq_time']])
results2 = model2.fit()
#+END_SRC

#+attr_ipynb: (slideshow . ((slide_type . notes)))
#+BEGIN_SRC jupyter-python :results none
datosModelo2['yhat'] = datosModelo2['cte']*results2.params['cte']+datosModelo2['time']*results2.params['time']+datosModelo2['sq_time']*results2.params['sq_time']
datosModelo2['ehat'] = results2.resid
datosModelo2['ehatDiff12'] = datosModelo2['ehat'].diff(12)
#+END_SRC


>>>>>>> eab5f6c (modificacion en la generación de ficheros png)
